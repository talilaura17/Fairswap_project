{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74be4130-5d0c-4fe1-b308-96740a67e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web3 import Web3\n",
    "\n",
    "# 創建一個 Web3 實例\n",
    "w3 = Web3()\n",
    "\n",
    "# w3.solidity_keccak(['string'], ['a']).hex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e22f9335-4d90-43bb-952e-b5c87d2f6196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n",
      "n\n",
      "n\n",
      "n\n",
      "n\n",
      "n\n",
      "n\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "import hashlib,sys\n",
    "    \n",
    "class MerkleTreeNode:\n",
    "    def __init__(self,value):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.value = value\n",
    "        if isinstance(value, bytes):\n",
    "            print(\"y\")\n",
    "            self.hashValue = w3.solidity_keccak(['bytes32'], [value]).hex()\n",
    "        else:\n",
    "            print(\"n\")\n",
    "            self.hashValue = w3.solidity_keccak(['string'], [value]).hex()\n",
    "    \n",
    "def buildTree(leaves,f):\n",
    "    nodes = []\n",
    "    for i in leaves:\n",
    "        nodes.append(MerkleTreeNode(i))\n",
    "\n",
    "    while len(nodes)!=1:\n",
    "        temp = []\n",
    "        for i in range(0,len(nodes),2):\n",
    "            node1 = nodes[i]\n",
    "            if i+1 < len(nodes):\n",
    "                node2 = nodes[i+1]\n",
    "            else:\n",
    "                temp.append(nodes[i])\n",
    "                break\n",
    "            f.write(\"Left child : \"+ node1.value + \" | Hash : \" + node1.hashValue +\" \\n\")\n",
    "            f.write(\"Right child : \"+ node2.value + \" | Hash : \" + node2.hashValue +\" \\n\")\n",
    "            concatenatedHash = node1.hashValue + node2.hashValue\n",
    "            parent = MerkleTreeNode(concatenatedHash)\n",
    "            parent.left = node1\n",
    "            parent.right = node2\n",
    "            f.write(\"Parent(concatenation of \"+ node1.value + \" and \" + node2.value + \") : \" +parent.value + \" | Hash : \" + parent.hashValue +\" \\n\")\n",
    "            temp.append(parent)\n",
    "        nodes = temp \n",
    "    return nodes[0]\n",
    "\n",
    "leaves = [\"a\", \"b\", \"c\", \"d\"]\n",
    "f = open(\"merkle.tree\", \"w\")\n",
    "root = buildTree(leaves,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d038efc9-80ef-4c3f-8436-36ec23beba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Left child : a | Hash : 0x3ac225168df54212a25c1c01fd35bebfea408fdac2e31ddd6f80a4bbf9a5f1cb \\r\\n'\n",
      "\n",
      "b'Right child : b | Hash : 0xb5553de315e0edf504d9150af82dafa5c4667fa618ed0a6f19c69b41166c5510 \\r\\n'\n",
      "\n",
      "b'Parent(concatenation of a and b) : 0x3ac225168df54212a25c1c01fd35bebfea408fdac2e31ddd6f80a4bbf9a5f1cb0xb5553de315e0edf504d9150af82dafa5c4667fa618ed0a6f19c69b41166c5510 | Hash : 0x5f532725975999c811ae13be41fb93a2dc961d792aabec5b07b1d961cddfded2 \\r\\n'\n",
      "\n",
      "b'Left child : c | Hash : 0x0b42b6393c1f53060fe3ddbfcd7aadcca894465a5a438f69c87d790b2299b9b2 \\r\\n'\n",
      "\n",
      "b'Right child : d | Hash : 0xf1918e8562236eb17adc8502332f4c9c82bc14e19bfc0aa10ab674ff75b3d2f3 \\r\\n'\n",
      "\n",
      "b'Parent(concatenation of c and d) : 0x0b42b6393c1f53060fe3ddbfcd7aadcca894465a5a438f69c87d790b2299b9b20xf1918e8562236eb17adc8502332f4c9c82bc14e19bfc0aa10ab674ff75b3d2f3 | Hash : 0xf2812278c73bfe791ea412701acc1697b7b14d4b50fed8c1ba7aa600d781118a \\r\\n'\n",
      "\n",
      "b'Left child : 0x3ac225168df54212a25c1c01fd35bebfea408fdac2e31ddd6f80a4bbf9a5f1cb0xb5553de315e0edf504d9150af82dafa5c4667fa618ed0a6f19c69b41166c5510 | Hash : 0x5f532725975999c811ae13be41fb93a2dc961d792aabec5b07b1d961cddfded2 \\r\\n'\n",
      "\n",
      "b'Right child : 0x0b42b6393c1f53060fe3ddbfcd7aadcca894465a5a438f69c87d790b2299b9b20xf1918e8562236eb17adc8502332f4c9c82bc14e19bfc0aa10ab674ff75b3d2f3 | Hash : 0xf2812278c73bfe791ea412701acc1697b7b14d4b50fed8c1ba7aa600d781118a \\r\\n'\n",
      "\n",
      "b'Parent(concatenation of 0x3ac225168df54212a25c1c01fd35bebfea408fdac2e31ddd6f80a4bbf9a5f1cb0xb5553de315e0edf504d9150af82dafa5c4667fa618ed0a6f19c69b41166c5510 and 0x0b42b6393c1f53060fe3ddbfcd7aadcca894465a5a438f69c87d790b2299b9b20xf1918e8562236eb17adc8502332f4c9c82bc14e19bfc0aa10ab674ff75b3d2f3) : 0x5f532725975999c811ae13be41fb93a2dc961d792aabec5b07b1d961cddfded20xf2812278c73bfe791ea412701acc1697b7b14d4b50fed8c1ba7aa600d781118a | Hash : 0xec5859a8693913943977a3f54b3b4a8ff95f8a69e7f299642bb4340f20ef2245 \\r\\n'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"merkle.tree\", \"rb\") as f:\n",
    "    data = f.readlines()\n",
    "for i in data:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f8655-5bac-4519-8980-dbaf85564b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5ba30b-6619-4c71-897d-f5889e661c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43cc0d5d-3665-4591-a99c-f12e64a30e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :  9722201502e620d70d78ee63045f3493812c206b988cbbe76c28918a7364fdbd\n",
      "1\n",
      "2 :  e99905ac9f9583a5737a07d20a7129343f486f5f549b42c05192046188ef5f66\n",
      "2\n",
      "3 :  4c89fefa814dbe46b640ca2ffb4682a1eaad32985c6604e98cc0a2fd76e49550\n",
      "3\n",
      "4 :  2ce80d2bc0bfe54c2499d066ac958c02304ce64ca318ae19a4636c32d583429c\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from pymerkle import InmemoryTree as MerkleTree\n",
    "\n",
    "tree = MerkleTree(algorithm='keccak_256')\n",
    "\n",
    "x = ['a', 'b', 'c', 'd']\n",
    "for i in x:\n",
    "    index = tree.append_entry(i.encode()) # leaf index\n",
    "    value = tree.get_leaf(index).hex()        # leaf hash\n",
    "    print(index,': ',value)\n",
    "    print(tree.get_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e67e687-7aad-4a39-b587-95324ac46a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "735a373e-5479-4a7f-822c-96e5d8a9ccdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " └─d0c277df...\n",
      "    ├──00d25e3e...\n",
      "    │   ├──97222015...\n",
      "    │   └──e99905ac...\n",
      "    └──0e4c742c...\n",
      "        ├──4c89fefa...\n",
      "        └──2ce80d2b...\n",
      "\n",
      "\n",
      "4\n",
      "d0c277dfc49909fb27fb9a2fc5000f8c9a49dfb3a1e54a2cc3f1bebe11c2b18c\n"
     ]
    }
   ],
   "source": [
    "print(tree)\n",
    "size = tree.get_size()    # number of leaves\n",
    "print(size)\n",
    "state = tree.get_state()    # current root-hash\n",
    "print(state.hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a539785-d07d-4bf4-9428-8a510806bd72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40007173-308a-449e-af2b-9a640b6853ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e4057e2e-0940-49b1-adf8-2644d9445958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import typing\n",
    "import hashlib\n",
    "from web3 import Web3\n",
    "\n",
    "# 創建一個 Web3 實例\n",
    "w3 = Web3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "47b3596c-5c72-4c98-a81c-acb501431248",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, left, right, value: str,content)-> None:\n",
    "        self.left: Node = left\n",
    "        self.right: Node = right\n",
    "        self.value = value\n",
    "        self.content = content\n",
    "\n",
    "    @staticmethod\n",
    "    #def hash(val: str) -> bytes:\n",
    "    #    return hashlib.sha256(val.encode('utf-8')).hexdigest()\n",
    "    \n",
    "    def keccak(val: str) -> bytes:\n",
    "        return w3.solidity_keccak(['string'], [val]).hex()\n",
    "\n",
    "    def __str__(self):\n",
    "        return(str(self.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bb5cf6b5-4cc5-485c-9dc1-b0787a310194",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MerkleTree:\n",
    "    def __init__(self, values: List[str])-> None:\n",
    "        self.__buildTree(values)\n",
    "\n",
    "    def __buildTree(self, values: List[str])-> None:\n",
    "\n",
    "        #leaves: List[Node] = [Node(None, None, Node.hash(e),e) for e in values]\n",
    "        #if len(leaves) % 2 ==1:\n",
    "        #   leaves.append(leaves[-1:][0])# duplicate last elem if odd number of elements\n",
    "        #   self.root: Node = self.__buildTreeRec(leaves)\n",
    "        \n",
    "        leaves: List[Node] = [Node(None, None, Node.keccak(e), e) for e in values] \n",
    "        if len(leaves) % 2 == 1:\n",
    "            leaves.append(leaves[-1:][0])  # duplicate last elem if odd number of elements\n",
    "        self.root = self.__buildTreeRec(leaves)\n",
    "\n",
    "    def __buildTreeRec(self, nodes: List[Node])-> Node:\n",
    "        half: int = len(nodes) // 2\n",
    "\n",
    "        if len(nodes) == 2:\n",
    "             return Node(nodes[0], nodes[1], w3.solidity_keccak(['bytes32', 'bytes32'], [nodes[0].value, nodes[1].value]).hex(), nodes[0].content+\"+\"+nodes[1].content)\n",
    "        \n",
    "        left: Node = self.__buildTreeRec(nodes[:half])\n",
    "        right: Node = self.__buildTreeRec(nodes[half:])\n",
    "        value: bytes = w3.solidity_keccak(['bytes32', 'bytes32'], [left.value, right.value]).hex()\n",
    "        #value: str = Node.hash(left.value + right.value)\n",
    "        content: str = self.__buildTreeRec(nodes[:half]).content+\"+\"+self.__buildTreeRec(nodes[half:]).content\n",
    "        return Node(left, right, value,content)\n",
    "    \n",
    "    \n",
    "    #---------------------------------------------------------\n",
    "    def printTree(self)-> None:\n",
    "        self.__printTreeRec(self.root)\n",
    "    def __printTreeRec(self, node)-> None:\n",
    "        if node != None:\n",
    "            if node.left != None:\n",
    "                print(\"Left: \"+str(node.left))\n",
    "                print(\"Right: \"+str(node.right))\n",
    "                #else:\n",
    "                #  print(\"Input\")\n",
    "\n",
    "                print(\"Value: \"+str(node.value))\n",
    "                print(\"Content: \"+str(node.content))\n",
    "                print(\"\")\n",
    "                self.__printTreeRec(node.left)\n",
    "                self.__printTreeRec(node.right)\n",
    "                \n",
    "    def getElem(self)-> None:\n",
    "        self._getElem(self.root)\n",
    "    def _getElem(self, node)-> None:\n",
    "        if node != None:\n",
    "            result.append(node.value)\n",
    "            self._getElem(node.left)\n",
    "            self._getElem(node.right)\n",
    "    \n",
    "    def getElemWithoutLeaf(self) -> None:\n",
    "        self._getElemWithoutLeaf(self.root)\n",
    "\n",
    "    def _getElemWithoutLeaf(self, node) -> None:\n",
    "        if node != None:\n",
    "            if node.left is None and node.right is None:\n",
    "                # 当前节点是叶子节点，不执行 append 操作\n",
    "                pass\n",
    "            else:\n",
    "                result.append(node.value)\n",
    "                self._getElemWithoutLeaf(node.left)\n",
    "                self._getElemWithoutLeaf(node.right)\n",
    "\n",
    "    def getRootHash(self)-> str:\n",
    "         return self.root.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d067ff6b-1bb7-48d9-a68b-8153f889a375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result個數:  15\n",
      "\n",
      "result=\n",
      "0xcd07272f4955ddcfdac38ff36dff9d3e4353498923679ab548ba87e34648e4a3\n",
      "0x68203f90e9d07dc5859259d7536e87a6ba9d345f2552b5b9de2999ddce9ce1bf\n",
      "0x805b21d846b189efaeb0377d6bb0d201b3872a363e607c25088f025b0c6ae1f8\n",
      "0x3ac225168df54212a25c1c01fd35bebfea408fdac2e31ddd6f80a4bbf9a5f1cb\n",
      "0xb5553de315e0edf504d9150af82dafa5c4667fa618ed0a6f19c69b41166c5510\n",
      "0xd253a52d4cb00de2895e85f2529e2976e6aaaa5c18106b68ab66813e14415669\n",
      "0x0b42b6393c1f53060fe3ddbfcd7aadcca894465a5a438f69c87d790b2299b9b2\n",
      "0xf1918e8562236eb17adc8502332f4c9c82bc14e19bfc0aa10ab674ff75b3d2f3\n",
      "0xf313fc9eb1c4864b1b8e78296656fb7831cc0ed46361bf3452db1c4cec430050\n",
      "0xf0b49bb4b0d9396e0315755ceafaa280707b32e75e6c9053f5cdf2679dcd5c6a\n",
      "0xa8982c89d80987fb9a510e25981ee9170206be21af3c8e0eb312ef1d3382e761\n",
      "0xd1e8aeb79500496ef3dc2e57ba746a8315d048b7a664a2bf948db4fa91960483\n",
      "0xe18a5c2ee5202ecdefed683f03145b1343304dbed01aecb94032b7f801844f0a\n",
      "0x14bcc435f49d130d189737f9762feb25c44ef5b886bef833e31a702af6be4748\n",
      "0xa766932420cc6e9072394bef2c036ad8972c44696fee29397bd5e2c06001f615\n",
      "\n",
      "root:  0xcd07272f4955ddcfdac38ff36dff9d3e4353498923679ab548ba87e34648e4a3\n"
     ]
    }
   ],
   "source": [
    "elems = ['a', 'b', 'c', 'd','e', 'f', 'g', 'h']\n",
    "# 建 merkle tree\n",
    "mtree = MerkleTree(elems)\n",
    "\n",
    "# 取出 merkle tree 的值\n",
    "result=[]\n",
    "mtree.getElem()\n",
    "print('result個數: ',len(result))\n",
    "\n",
    "print(\"\")\n",
    "print('result=')\n",
    "print(*result, sep = \"\\n\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"root: \", mtree.getRootHash())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "05b9e4b8-abb7-40be-8d5f-c990da548efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left: 0x68203f90e9d07dc5859259d7536e87a6ba9d345f2552b5b9de2999ddce9ce1bf\n",
      "Right: 0xf313fc9eb1c4864b1b8e78296656fb7831cc0ed46361bf3452db1c4cec430050\n",
      "Value: 0xcd07272f4955ddcfdac38ff36dff9d3e4353498923679ab548ba87e34648e4a3\n",
      "Content: a+b+c+d+e+f+g+h\n",
      "\n",
      "Left: 0x805b21d846b189efaeb0377d6bb0d201b3872a363e607c25088f025b0c6ae1f8\n",
      "Right: 0xd253a52d4cb00de2895e85f2529e2976e6aaaa5c18106b68ab66813e14415669\n",
      "Value: 0x68203f90e9d07dc5859259d7536e87a6ba9d345f2552b5b9de2999ddce9ce1bf\n",
      "Content: a+b+c+d\n",
      "\n",
      "Left: 0x3ac225168df54212a25c1c01fd35bebfea408fdac2e31ddd6f80a4bbf9a5f1cb\n",
      "Right: 0xb5553de315e0edf504d9150af82dafa5c4667fa618ed0a6f19c69b41166c5510\n",
      "Value: 0x805b21d846b189efaeb0377d6bb0d201b3872a363e607c25088f025b0c6ae1f8\n",
      "Content: a+b\n",
      "\n",
      "Left: 0x0b42b6393c1f53060fe3ddbfcd7aadcca894465a5a438f69c87d790b2299b9b2\n",
      "Right: 0xf1918e8562236eb17adc8502332f4c9c82bc14e19bfc0aa10ab674ff75b3d2f3\n",
      "Value: 0xd253a52d4cb00de2895e85f2529e2976e6aaaa5c18106b68ab66813e14415669\n",
      "Content: c+d\n",
      "\n",
      "Left: 0xf0b49bb4b0d9396e0315755ceafaa280707b32e75e6c9053f5cdf2679dcd5c6a\n",
      "Right: 0xe18a5c2ee5202ecdefed683f03145b1343304dbed01aecb94032b7f801844f0a\n",
      "Value: 0xf313fc9eb1c4864b1b8e78296656fb7831cc0ed46361bf3452db1c4cec430050\n",
      "Content: e+f+g+h\n",
      "\n",
      "Left: 0xa8982c89d80987fb9a510e25981ee9170206be21af3c8e0eb312ef1d3382e761\n",
      "Right: 0xd1e8aeb79500496ef3dc2e57ba746a8315d048b7a664a2bf948db4fa91960483\n",
      "Value: 0xf0b49bb4b0d9396e0315755ceafaa280707b32e75e6c9053f5cdf2679dcd5c6a\n",
      "Content: e+f\n",
      "\n",
      "Left: 0x14bcc435f49d130d189737f9762feb25c44ef5b886bef833e31a702af6be4748\n",
      "Right: 0xa766932420cc6e9072394bef2c036ad8972c44696fee29397bd5e2c06001f615\n",
      "Value: 0xe18a5c2ee5202ecdefed683f03145b1343304dbed01aecb94032b7f801844f0a\n",
      "Content: g+h\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtree.printTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "96d571f0-629c-4191-8e15-121e85683e76",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "getElemWithoutLeaf() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6784\\2884492504.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetElemWithoutLeaf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: getElemWithoutLeaf() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "mtree.getElemWithoutLeaf('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9955921-f080-4346-82d4-05d874c3f80a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "{'message': 'VM Exception while processing transaction: invalid opcode', 'stack': 'RuntimeError: VM Exception while processing transaction: invalid opcode\\n    at LegacyTransaction.fillFromResult (C:\\\\Program Files\\\\WindowsApps\\\\GanacheUI_2.7.1.0_x64__rb4352f0jd4m2\\\\app\\\\resources\\\\static\\\\node\\\\node_modules\\\\ganache\\\\dist\\\\node\\\\1.js:2:12745)\\n    at Miner.<anonymous> (C:\\\\Program Files\\\\WindowsApps\\\\GanacheUI_2.7.1.0_x64__rb4352f0jd4m2\\\\app\\\\resources\\\\static\\\\node\\\\node_modules\\\\ganache\\\\dist\\\\node\\\\1.js:2:36703)\\n    at async Miner.<anonymous> (C:\\\\Program Files\\\\WindowsApps\\\\GanacheUI_2.7.1.0_x64__rb4352f0jd4m2\\\\app\\\\resources\\\\static\\\\node\\\\node_modules\\\\ganache\\\\dist\\\\node\\\\1.js:2:35116)\\n    at async Miner.mine (C:\\\\Program Files\\\\WindowsApps\\\\GanacheUI_2.7.1.0_x64__rb4352f0jd4m2\\\\app\\\\resources\\\\static\\\\node\\\\node_modules\\\\ganache\\\\dist\\\\node\\\\1.js:2:39680)\\n    at async Blockchain.mine (C:\\\\Program Files\\\\WindowsApps\\\\GanacheUI_2.7.1.0_x64__rb4352f0jd4m2\\\\app\\\\resources\\\\static\\\\node\\\\node_modules\\\\ganache\\\\dist\\\\node\\\\1.js:2:60063)\\n    at async Promise.all (index 0)\\n    at async TransactionPool.emit (C:\\\\Program Files\\\\WindowsApps\\\\GanacheUI_2.7.1.0_x64__rb4352f0jd4m2\\\\app\\\\resources\\\\static\\\\node\\\\node_modules\\\\ganache\\\\node_modules\\\\emittery\\\\index.js:303:3)', 'code': -32000, 'name': 'RuntimeError', 'data': {'hash': '0x189e7bd7ca1b0d9000174d607922d59f63dd12a535931feb8c10fe80647cbdf1', 'programCounter': 9, 'result': '0x189e7bd7ca1b0d9000174d607922d59f63dd12a535931feb8c10fe80647cbdf1', 'reason': None, 'message': 'invalid opcode'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m signed_transaction \u001b[38;5;241m=\u001b[39m w3\u001b[38;5;241m.\u001b[39meth\u001b[38;5;241m.\u001b[39maccount\u001b[38;5;241m.\u001b[39msign_transaction(transaction, private_key)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# 發送交易並等待確認\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m tx_hash \u001b[38;5;241m=\u001b[39m w3\u001b[38;5;241m.\u001b[39meth\u001b[38;5;241m.\u001b[39msend_raw_transaction(signed_transaction\u001b[38;5;241m.\u001b[39mrawTransaction)\n\u001b[0;32m     35\u001b[0m tx_receipt \u001b[38;5;241m=\u001b[39m w3\u001b[38;5;241m.\u001b[39meth\u001b[38;5;241m.\u001b[39mwait_for_transaction_receipt(tx_hash)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# 獲取已部署合約的地址\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\web3\\eth\\eth.py:396\u001b[0m, in \u001b[0;36mEth.send_raw_transaction\u001b[1;34m(self, transaction)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_raw_transaction\u001b[39m(\u001b[38;5;28mself\u001b[39m, transaction: Union[HexStr, \u001b[38;5;28mbytes\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m HexBytes:\n\u001b[1;32m--> 396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_raw_transaction(transaction)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\web3\\module.py:75\u001b[0m, in \u001b[0;36mretrieve_blocking_method_call_fn.<locals>.caller\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LogFilter(eth_module\u001b[38;5;241m=\u001b[39mmodule, filter_id\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mfilter_id)\n\u001b[0;32m     70\u001b[0m (\n\u001b[0;32m     71\u001b[0m     result_formatters,\n\u001b[0;32m     72\u001b[0m     error_formatters,\n\u001b[0;32m     73\u001b[0m     null_result_formatters,\n\u001b[0;32m     74\u001b[0m ) \u001b[38;5;241m=\u001b[39m response_formatters\n\u001b[1;32m---> 75\u001b[0m result \u001b[38;5;241m=\u001b[39m w3\u001b[38;5;241m.\u001b[39mmanager\u001b[38;5;241m.\u001b[39mrequest_blocking(\n\u001b[0;32m     76\u001b[0m     method_str, params, error_formatters, null_result_formatters\n\u001b[0;32m     77\u001b[0m )\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m apply_result_formatters(result_formatters, result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\web3\\manager.py:330\u001b[0m, in \u001b[0;36mRequestManager.request_blocking\u001b[1;34m(self, method, params, error_formatters, null_result_formatters)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03mMake a synchronous request using the provider\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    329\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(method, params)\n\u001b[1;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformatted_response(\n\u001b[0;32m    331\u001b[0m     response, params, error_formatters, null_result_formatters\n\u001b[0;32m    332\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\web3\\manager.py:293\u001b[0m, in \u001b[0;36mRequestManager.formatted_response\u001b[1;34m(response, params, error_formatters, null_result_formatters)\u001b[0m\n\u001b[0;32m    287\u001b[0m         _raise_bad_response_format(\n\u001b[0;32m    288\u001b[0m             response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] must be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    289\u001b[0m         )\n\u001b[0;32m    291\u001b[0m     apply_error_formatters(error_formatters, response)\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error)\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# Format and validate results\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;66;03m# Null values for result should apply null_result_formatters\u001b[39;00m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;66;03m# Skip when result not present in the response (fallback to False)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: {'message': 'VM Exception while processing transaction: invalid opcode', 'stack': 'RuntimeError: VM Exception while processing transaction: invalid opcode\\n    at LegacyTransaction.fillFromResult (C:\\\\Program Files\\\\WindowsApps\\\\GanacheUI_2.7.1.0_x64__rb4352f0jd4m2\\\\app\\\\resources\\\\static\\\\node\\\\node_modules\\\\ganache\\\\dist\\\\node\\\\1.js:2:12745)\\n    at Miner.<anonymous> (C:\\\\Program Files\\\\WindowsApps\\\\GanacheUI_2.7.1.0_x64__rb4352f0jd4m2\\\\app\\\\resources\\\\static\\\\node\\\\node_modules\\\\ganache\\\\dist\\\\node\\\\1.js:2:36703)\\n    at async Miner.<anonymous> (C:\\\\Program Files\\\\WindowsApps\\\\GanacheUI_2.7.1.0_x64__rb4352f0jd4m2\\\\app\\\\resources\\\\static\\\\node\\\\node_modules\\\\ganache\\\\dist\\\\node\\\\1.js:2:35116)\\n    at async Miner.mine (C:\\\\Program Files\\\\WindowsApps\\\\GanacheUI_2.7.1.0_x64__rb4352f0jd4m2\\\\app\\\\resources\\\\static\\\\node\\\\node_modules\\\\ganache\\\\dist\\\\node\\\\1.js:2:39680)\\n    at async Blockchain.mine (C:\\\\Program Files\\\\WindowsApps\\\\GanacheUI_2.7.1.0_x64__rb4352f0jd4m2\\\\app\\\\resources\\\\static\\\\node\\\\node_modules\\\\ganache\\\\dist\\\\node\\\\1.js:2:60063)\\n    at async Promise.all (index 0)\\n    at async TransactionPool.emit (C:\\\\Program Files\\\\WindowsApps\\\\GanacheUI_2.7.1.0_x64__rb4352f0jd4m2\\\\app\\\\resources\\\\static\\\\node\\\\node_modules\\\\ganache\\\\node_modules\\\\emittery\\\\index.js:303:3)', 'code': -32000, 'name': 'RuntimeError', 'data': {'hash': '0x189e7bd7ca1b0d9000174d607922d59f63dd12a535931feb8c10fe80647cbdf1', 'programCounter': 9, 'result': '0x189e7bd7ca1b0d9000174d607922d59f63dd12a535931feb8c10fe80647cbdf1', 'reason': None, 'message': 'invalid opcode'}}"
     ]
    }
   ],
   "source": [
    "from web3 import Web3\n",
    "import json\n",
    "\n",
    "# 連接到本地以太坊節點\n",
    "w3 = Web3(Web3.HTTPProvider('http://127.0.0.1:7545'))\n",
    "\n",
    "# 檢查連接\n",
    "assert w3.is_connected(), \"Failed to connect to the Ethereum node\"\n",
    "\n",
    "# 設置帳戶和私鑰\n",
    "account = '0xD2ba6B552Aa333b15b69DB2CB173C8c50415e0cd'  # 你的以太坊帳戶地址\n",
    "private_key = '0x4e768f45a9106f44ee9718de6eaee54ec09b0dc72a835f9a17c6848a0db55955'  # 你的私鑰\n",
    "\n",
    "# 加載智能合約ABI\n",
    "with open('abi6.json', 'r') as file:\n",
    "    contract_abi = json.load(file)\n",
    "contract_bytecode = '0x67226767ba5F3cA978B7b69268E8518caEe944f2'\n",
    "\n",
    "# 部署合約\n",
    "ExampleContract = w3.eth.contract(abi=contract_abi, bytecode=contract_bytecode)\n",
    "\n",
    "# 建立交易\n",
    "transaction = ExampleContract.constructor().build_transaction({\n",
    "    'from': account,\n",
    "    'nonce': w3.eth.get_transaction_count(account),\n",
    "    'gas': 2000000,\n",
    "    'gasPrice': w3.to_wei('50', 'gwei')\n",
    "})\n",
    "\n",
    "# 使用私鑰簽名交易\n",
    "signed_transaction = w3.eth.account.sign_transaction(transaction, private_key)\n",
    "\n",
    "# 發送交易並等待確認\n",
    "tx_hash = w3.eth.send_raw_transaction(signed_transaction.rawTransaction)\n",
    "tx_receipt = w3.eth.wait_for_transaction_receipt(tx_hash)\n",
    "\n",
    "# 獲取已部署合約的地址\n",
    "contract_address = tx_receipt.contractAddress\n",
    "\n",
    "# 創建合約實例\n",
    "contract_instance = w3.eth.contract(address=contract_address, abi=contract_abi)\n",
    "\n",
    "# 調用合約函數\n",
    "sij, kij, s_bar, s_recovered = contract_instance.functions.example().call()\n",
    "\n",
    "print(f\"sij (random):\\t{sij}\")\n",
    "print(f\"kij (random):\\t{kij}\")\n",
    "print(f\"s_bar (encrypted):\\t{s_bar}\")\n",
    "print(f\"sij (recovered):\\t{s_recovered}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a62655fb-d7be-4c69-8657-21377f42d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, n):\n",
    "    # 确定每块的大小\n",
    "    block_size = len(data) // n\n",
    "    remainder = len(data) % n\n",
    "    blocks = []\n",
    "\n",
    "    # 将数据分成n块\n",
    "    start = 0\n",
    "    for i in range(n):\n",
    "        end = start + block_size + (1 if i < remainder else 0)\n",
    "        blocks.append(data[start:end])\n",
    "        start = end\n",
    "\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3420d4aa-cd8a-4935-bba9-8a2cff772ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elems1個數:  8\n",
      "elems1=\n",
      "1234567890123456789012345678 | 901234567890123456789012345 | 678901234567890123456789012 | 345678901234567890123456789 | 012345678901234567890123456 | 7890abcdefgabcdefgabcdefgab | cdefgabcdefgabcdefgabcdefga | bcdefgabcdefgabcdefgabcdefg\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data1.txt'\n",
    "# block個數只能4 8 16 32 ...\n",
    "n = 8\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "elems1 = split_data(data, n)\n",
    "\n",
    "print('elems1個數: ',len(elems1))\n",
    "print('elems1=')\n",
    "print(*elems1, sep = \" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48064161-27e2-458c-84bd-c0a82c2d9789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2882f27a-dd8a-4557-a693-8da259032730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merkle Tree:\n",
      "('0x622b1092273fe26f6a2c370a5c34a690337e7f802f2fa5006b40790bd3f7d69b', '0x7012f98e24c6b2f609d365c959c99a9bc691d6939cc7162e679fb1226697a56b', HexBytes('0x233f0359f6becf36146a180d79b3d921d9232e8c751167e12b71f48c8ba404d0'))\n",
      "('0x1988284e7250800b37f11b3fbe7b25ad52b72cb5caff67934f69015a4263ffb5', '0xa706adce5b41b9fab05150b0ad504f75d877a594784ce6bcc1bb8c7590296d74', HexBytes('0x250a7f5c9c504685a3e1a77bbce0754996ac1b0f856cc28992907bb9caa4f95d'))\n",
      "('0x2886ace34a4bb5b60caa6a5670d1286e5ac56b3bad03631acb759174b3613ea4', '0x73490cae58b2b181e535c9c4ea4895cbfa2e6757db77f12e1f33621efa935176', HexBytes('0xe087d3fe6cd3c7d6bea24b77acb2701c255f101dbc5ba4fc06c7c4529f70681b'))\n",
      "('0x75b69f5bb05a9e6d2eeb54bcedc110d1c0ed8987860600c6c6fba8b9c2153040', '0xa9913c5f85d47ea0a0d432f975217dbf2f78acbb64576990b71699bf63a76438', HexBytes('0xe8d7de23ec090d538f6dc383f2f64285811bf6c3a2f133f09d7b893b41cfc6aa'))\n",
      "(HexBytes('0x233f0359f6becf36146a180d79b3d921d9232e8c751167e12b71f48c8ba404d0'), HexBytes('0x250a7f5c9c504685a3e1a77bbce0754996ac1b0f856cc28992907bb9caa4f95d'), HexBytes('0x3c2e5a2e8dba6178391b772cd9fa501402bb1f3287ee3061668936816df8c7b9'))\n",
      "(HexBytes('0xe087d3fe6cd3c7d6bea24b77acb2701c255f101dbc5ba4fc06c7c4529f70681b'), HexBytes('0xe8d7de23ec090d538f6dc383f2f64285811bf6c3a2f133f09d7b893b41cfc6aa'), HexBytes('0x1ab7c24c0678d12c603eceb047de727ddc0e04fd40cb1d36cf9f4f6c16961880'))\n",
      "(HexBytes('0x3c2e5a2e8dba6178391b772cd9fa501402bb1f3287ee3061668936816df8c7b9'), HexBytes('0x1ab7c24c0678d12c603eceb047de727ddc0e04fd40cb1d36cf9f4f6c16961880'), HexBytes('0xc894dfc9419592f9bd2728ec39612991eccc5ac113d281f83603563f1bba74b0'))\n",
      "b\"\\xc8\\x94\\xdf\\xc9A\\x95\\x92\\xf9\\xbd'(\\xec9a)\\x91\\xec\\xccZ\\xc1\\x13\\xd2\\x81\\xf86\\x03V?\\x1b\\xbat\\xb0\"\n",
      "Root: 0xc894dfc9419592f9bd2728ec39612991eccc5ac113d281f83603563f1bba74b0\n"
     ]
    }
   ],
   "source": [
    "from web3 import Web3\n",
    "from collections import deque\n",
    "\n",
    "# 創建一個 Web3 實例\n",
    "w3 = Web3()\n",
    "\n",
    "def hash_pair(left, right):\n",
    "    return w3.solidity_keccak(['bytes32', 'bytes32'], [left, right])\n",
    "\n",
    "def build_merkle_tree(leaves):\n",
    "    if not leaves:\n",
    "        raise ValueError(\"The list of leaves cannot be empty\")\n",
    "\n",
    "    # Hash the leaves using Web3's solidity_keccak\n",
    "    hashed_leaves = [w3.solidity_keccak(['string'], [leaf]).hex() if isinstance(leaf, str) else leaf for leaf in leaves]\n",
    "\n",
    "    # Use deque for efficient pop from left\n",
    "    current_level = deque(hashed_leaves)\n",
    "    \n",
    "    # List to store the entire tree\n",
    "    tree = []\n",
    "\n",
    "    while len(current_level) > 1:\n",
    "        next_level = deque()\n",
    "        \n",
    "        while len(current_level) > 1:\n",
    "            left = current_level.popleft()\n",
    "            right = current_level.popleft()\n",
    "            parent_hash = hash_pair(left, right)\n",
    "            next_level.append(parent_hash)\n",
    "            tree.append((left, right, parent_hash))  # Store the tree structure\n",
    "        \n",
    "        if current_level:  # If odd number of elements, carry the last element to the next level\n",
    "            next_level.append(current_level.popleft())\n",
    "        \n",
    "        current_level = next_level\n",
    "\n",
    "    # The root of the tree\n",
    "    root = current_level[0]\n",
    "    tree.append(root)\n",
    "\n",
    "    return tree, root\n",
    "\n",
    "# Example usage\n",
    "leaves = ['data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7', 'data8']\n",
    "tree, root = build_merkle_tree(leaves)\n",
    "print(\"Merkle Tree:\")\n",
    "for node in tree:\n",
    "    print(node)\n",
    "print(\"Root:\", root.hex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc67acfe-8d52-451b-aa3d-0474e4870579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merkle Tree Hash Mapping:\n",
      "Hash: 0x622b1092273fe26f6a2c370a5c34a690337e7f802f2fa5006b40790bd3f7d69b -> Original Value: data1\n",
      "Hash: 0x7012f98e24c6b2f609d365c959c99a9bc691d6939cc7162e679fb1226697a56b -> Original Value: data2\n",
      "Hash: 0x1988284e7250800b37f11b3fbe7b25ad52b72cb5caff67934f69015a4263ffb5 -> Original Value: data3\n",
      "Hash: 0xa706adce5b41b9fab05150b0ad504f75d877a594784ce6bcc1bb8c7590296d74 -> Original Value: data4\n",
      "Hash: 0x2886ace34a4bb5b60caa6a5670d1286e5ac56b3bad03631acb759174b3613ea4 -> Original Value: data5\n",
      "Hash: 0x73490cae58b2b181e535c9c4ea4895cbfa2e6757db77f12e1f33621efa935176 -> Original Value: data6\n",
      "Hash: 0x75b69f5bb05a9e6d2eeb54bcedc110d1c0ed8987860600c6c6fba8b9c2153040 -> Original Value: data7\n",
      "Hash: 0xa9913c5f85d47ea0a0d432f975217dbf2f78acbb64576990b71699bf63a76438 -> Original Value: data8\n",
      "Hash: 0x233f0359f6becf36146a180d79b3d921d9232e8c751167e12b71f48c8ba404d0 -> Original Value: ('data1', 'data2')\n",
      "Hash: 0x250a7f5c9c504685a3e1a77bbce0754996ac1b0f856cc28992907bb9caa4f95d -> Original Value: ('data3', 'data4')\n",
      "Hash: 0xe087d3fe6cd3c7d6bea24b77acb2701c255f101dbc5ba4fc06c7c4529f70681b -> Original Value: ('data5', 'data6')\n",
      "Hash: 0xe8d7de23ec090d538f6dc383f2f64285811bf6c3a2f133f09d7b893b41cfc6aa -> Original Value: ('data7', 'data8')\n",
      "Hash: 0x3c2e5a2e8dba6178391b772cd9fa501402bb1f3287ee3061668936816df8c7b9 -> Original Value: (('data1', 'data2'), ('data3', 'data4'))\n",
      "Hash: 0x1ab7c24c0678d12c603eceb047de727ddc0e04fd40cb1d36cf9f4f6c16961880 -> Original Value: (('data5', 'data6'), ('data7', 'data8'))\n",
      "Hash: 0xc894dfc9419592f9bd2728ec39612991eccc5ac113d281f83603563f1bba74b0 -> Original Value: ((('data1', 'data2'), ('data3', 'data4')), (('data5', 'data6'), ('data7', 'data8')))\n",
      "Root Hash: 0xc894dfc9419592f9bd2728ec39612991eccc5ac113d281f83603563f1bba74b0\n",
      "{'0x622b1092273fe26f6a2c370a5c34a690337e7f802f2fa5006b40790bd3f7d69b': 'data1', '0x7012f98e24c6b2f609d365c959c99a9bc691d6939cc7162e679fb1226697a56b': 'data2', '0x1988284e7250800b37f11b3fbe7b25ad52b72cb5caff67934f69015a4263ffb5': 'data3', '0xa706adce5b41b9fab05150b0ad504f75d877a594784ce6bcc1bb8c7590296d74': 'data4', '0x2886ace34a4bb5b60caa6a5670d1286e5ac56b3bad03631acb759174b3613ea4': 'data5', '0x73490cae58b2b181e535c9c4ea4895cbfa2e6757db77f12e1f33621efa935176': 'data6', '0x75b69f5bb05a9e6d2eeb54bcedc110d1c0ed8987860600c6c6fba8b9c2153040': 'data7', '0xa9913c5f85d47ea0a0d432f975217dbf2f78acbb64576990b71699bf63a76438': 'data8', '0x233f0359f6becf36146a180d79b3d921d9232e8c751167e12b71f48c8ba404d0': ('data1', 'data2'), '0x250a7f5c9c504685a3e1a77bbce0754996ac1b0f856cc28992907bb9caa4f95d': ('data3', 'data4'), '0xe087d3fe6cd3c7d6bea24b77acb2701c255f101dbc5ba4fc06c7c4529f70681b': ('data5', 'data6'), '0xe8d7de23ec090d538f6dc383f2f64285811bf6c3a2f133f09d7b893b41cfc6aa': ('data7', 'data8'), '0x3c2e5a2e8dba6178391b772cd9fa501402bb1f3287ee3061668936816df8c7b9': (('data1', 'data2'), ('data3', 'data4')), '0x1ab7c24c0678d12c603eceb047de727ddc0e04fd40cb1d36cf9f4f6c16961880': (('data5', 'data6'), ('data7', 'data8')), '0xc894dfc9419592f9bd2728ec39612991eccc5ac113d281f83603563f1bba74b0': ((('data1', 'data2'), ('data3', 'data4')), (('data5', 'data6'), ('data7', 'data8')))}\n"
     ]
    }
   ],
   "source": [
    "from web3 import Web3\n",
    "from collections import deque\n",
    "\n",
    "# 創建一個 Web3 實例\n",
    "w3 = Web3()\n",
    "\n",
    "def hash_pair(left, right):\n",
    "    return w3.solidity_keccak(['bytes32', 'bytes32'], [left, right]).hex()\n",
    "\n",
    "def build_merkle_tree(leaves):\n",
    "    if not leaves:\n",
    "        raise ValueError(\"The list of leaves cannot be empty\")\n",
    "\n",
    "    # Hash the leaves using Web3's solidity_keccak and store the mappings\n",
    "    hashed_leaves = [(w3.solidity_keccak(['string'], [leaf]).hex(), leaf) if isinstance(leaf, str) else (leaf, leaf) for leaf in leaves]\n",
    "\n",
    "    # Use deque for efficient pop from left\n",
    "    current_level = deque(hashed_leaves)\n",
    "    \n",
    "    # Dictionary to store the mappings from hash to original values or node pairs\n",
    "    hash_mapping = {hashed: original for hashed, original in hashed_leaves}\n",
    "\n",
    "    while len(current_level) > 1:\n",
    "        next_level = deque()\n",
    "        \n",
    "        while len(current_level) > 1:\n",
    "            left_hashed, left_value = current_level.popleft()\n",
    "            right_hashed, right_value = current_level.popleft()\n",
    "            parent_hash = hash_pair(left_hashed, right_hashed)\n",
    "            next_level.append((parent_hash, (left_value, right_value)))\n",
    "            hash_mapping[parent_hash] = (left_value, right_value)\n",
    "        \n",
    "        if current_level:  # If odd number of elements, carry the last element to the next level\n",
    "            next_level.append(current_level.popleft())\n",
    "        \n",
    "        current_level = next_level\n",
    "\n",
    "    # The root of the tree\n",
    "    root_hashed, root_value = current_level[0]\n",
    "    hash_mapping[root_hashed] = root_value\n",
    "\n",
    "    return hash_mapping, root_hashed\n",
    "\n",
    "# Example usage\n",
    "leaves = ['data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7', 'data8']\n",
    "hash_mapping, root = build_merkle_tree(leaves)\n",
    "\n",
    "print(\"Merkle Tree Hash Mapping:\")\n",
    "for hash_value, original_value in hash_mapping.items():\n",
    "    print(f\"Hash: {hash_value} -> Original Value: {original_value}\")\n",
    "print(\"Root Hash:\", root)\n",
    "\n",
    "print(hash_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a96182a-ca57-4e06-9355-b690471f8058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merkle Proof: ['0xf1918e8562236eb17adc8502332f4c9c82bc14e19bfc0aa10ab674ff75b3d2f3', '0x805b21d846b189efaeb0377d6bb0d201b3872a363e607c25088f025b0c6ae1f8']\n",
      "False\n",
      "\n",
      "Merkle Tree Hash Mapping:\n",
      "Hash: 0x3ac225168df54212a25c1c01fd35bebfea408fdac2e31ddd6f80a4bbf9a5f1cb -> Original Value: a\n",
      "Hash: 0xb5553de315e0edf504d9150af82dafa5c4667fa618ed0a6f19c69b41166c5510 -> Original Value: b\n",
      "Hash: 0x0b42b6393c1f53060fe3ddbfcd7aadcca894465a5a438f69c87d790b2299b9b2 -> Original Value: c\n",
      "Hash: 0xf1918e8562236eb17adc8502332f4c9c82bc14e19bfc0aa10ab674ff75b3d2f3 -> Original Value: d\n",
      "Hash: 0xa8982c89d80987fb9a510e25981ee9170206be21af3c8e0eb312ef1d3382e761 -> Original Value: e\n",
      "Hash: 0xd1e8aeb79500496ef3dc2e57ba746a8315d048b7a664a2bf948db4fa91960483 -> Original Value: f\n",
      "Hash: 0x14bcc435f49d130d189737f9762feb25c44ef5b886bef833e31a702af6be4748 -> Original Value: g\n",
      "Hash: 0xa766932420cc6e9072394bef2c036ad8972c44696fee29397bd5e2c06001f615 -> Original Value: h\n",
      "Hash: 0x805b21d846b189efaeb0377d6bb0d201b3872a363e607c25088f025b0c6ae1f8 -> Original Value: ('a', 'b')\n",
      "Hash: 0xd253a52d4cb00de2895e85f2529e2976e6aaaa5c18106b68ab66813e14415669 -> Original Value: ('c', 'd')\n",
      "Hash: 0xf0b49bb4b0d9396e0315755ceafaa280707b32e75e6c9053f5cdf2679dcd5c6a -> Original Value: ('e', 'f')\n",
      "Hash: 0xe18a5c2ee5202ecdefed683f03145b1343304dbed01aecb94032b7f801844f0a -> Original Value: ('g', 'h')\n",
      "Hash: 0x68203f90e9d07dc5859259d7536e87a6ba9d345f2552b5b9de2999ddce9ce1bf -> Original Value: (('a', 'b'), ('c', 'd'))\n",
      "Hash: 0xf313fc9eb1c4864b1b8e78296656fb7831cc0ed46361bf3452db1c4cec430050 -> Original Value: (('e', 'f'), ('g', 'h'))\n",
      "Hash: 0xcd07272f4955ddcfdac38ff36dff9d3e4353498923679ab548ba87e34648e4a3 -> Original Value: ((('a', 'b'), ('c', 'd')), (('e', 'f'), ('g', 'h')))\n"
     ]
    }
   ],
   "source": [
    "from web3 import Web3\n",
    "from collections import deque\n",
    "\n",
    "# 创建一个 Web3 实例\n",
    "w3 = Web3()\n",
    "\n",
    "def hash_pair(left, right):\n",
    "    return w3.solidity_keccak(['bytes32', 'bytes32'], [left, right]).hex()\n",
    "\n",
    "def build_merkle_tree(leaves):\n",
    "    if not leaves:\n",
    "        raise ValueError(\"The list of leaves cannot be empty\")\n",
    "\n",
    "    # Hash the leaves using Web3's solidity_keccak and store the mappings\n",
    "    hashed_leaves = [(w3.solidity_keccak(['string'], [leaf]).hex(), leaf) if isinstance(leaf, str) else (leaf, leaf) for leaf in leaves]\n",
    "\n",
    "    # Use deque for efficient pop from left\n",
    "    current_level = deque(hashed_leaves)\n",
    "    \n",
    "    # Dictionary to store the mappings from hash to original values or node pairs\n",
    "    hash_mapping = {hashed: original for hashed, original in hashed_leaves}\n",
    "    proof_mapping = {}  # Dictionary to store proof nodes for each leaf\n",
    "\n",
    "    while len(current_level) > 1:\n",
    "        next_level = deque()\n",
    "        \n",
    "        while len(current_level) > 1:\n",
    "            left_hashed, left_value = current_level.popleft()\n",
    "            right_hashed, right_value = current_level.popleft()\n",
    "            parent_hash = hash_pair(left_hashed, right_hashed)\n",
    "            next_level.append((parent_hash, (left_value, right_value)))\n",
    "            hash_mapping[parent_hash] = (left_value, right_value)\n",
    "            \n",
    "            # Store proof for each child node\n",
    "            if left_hashed not in proof_mapping:\n",
    "                proof_mapping[left_hashed] = []\n",
    "            proof_mapping[left_hashed].append(right_hashed)\n",
    "            \n",
    "            if right_hashed not in proof_mapping:\n",
    "                proof_mapping[right_hashed] = []\n",
    "            proof_mapping[right_hashed].append(left_hashed)\n",
    "        \n",
    "        if current_level:  # If odd number of elements, carry the last element to the next level\n",
    "            next_level.append(current_level.popleft())\n",
    "        \n",
    "        current_level = next_level\n",
    "\n",
    "    # The root of the tree\n",
    "    root_hashed, root_value = current_level[0]\n",
    "    hash_mapping[root_hashed] = root_value\n",
    "\n",
    "    return hash_mapping, proof_mapping, root_hashed\n",
    "\n",
    "def get_merkle_proof(value, hash_mapping, proof_mapping):\n",
    "    if isinstance(value, str):\n",
    "        value_hash = w3.solidity_keccak(['string'], [value]).hex()\n",
    "    else:\n",
    "        value_hash = value\n",
    "    \n",
    "    proof = []\n",
    "    current_hash = value_hash\n",
    "    \n",
    "    while current_hash in proof_mapping:\n",
    "        siblings = proof_mapping[current_hash]\n",
    "        proof.extend(siblings)\n",
    "        \n",
    "        if len(siblings) == 1:  # If only one sibling, it means it's the last element in the level\n",
    "            sibling_hash = siblings[0]\n",
    "            current_hash = hash_pair(current_hash, sibling_hash)\n",
    "        else:\n",
    "            current_hash = hash_pair(current_hash, siblings[0])\n",
    "    \n",
    "    return proof\n",
    "\n",
    "def verify_merkle_proof(value, index, proof, root):\n",
    "    if isinstance(value, str):\n",
    "        value_hash = w3.solidity_keccak(['string'], [value]).hex()\n",
    "    else:\n",
    "        value_hash = value\n",
    "    \n",
    "    current_hash = value_hash\n",
    "    \n",
    "    for sibling_hash in proof:\n",
    "        if index%2==1:\n",
    "            current_hash = hash_pair(current_hash, sibling_hash)\n",
    "        else:\n",
    "            current_hash = hash_pair(sibling_hash, current_hash)\n",
    "    \n",
    "    return current_hash == root\n",
    "\n",
    "# Example usage\n",
    "leaves = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "hash_mapping, proof_mapping, root = build_merkle_tree(leaves)\n",
    "\n",
    "# Value to verify\n",
    "value_to_verify = 'c'\n",
    "index = 2\n",
    "\n",
    "\n",
    "# Generate Merkle proof for the value\n",
    "proof = get_merkle_proof(value_to_verify, hash_mapping, proof_mapping)\n",
    "print(\"Merkle Proof:\", proof)\n",
    "\n",
    "\n",
    "# Verify the proof\n",
    "is_valid = verify_merkle_proof(value_to_verify, index, proof, root)\n",
    "\n",
    "print(is_valid)\n",
    "    \n",
    "    \n",
    "print(\"\\nMerkle Tree Hash Mapping:\")\n",
    "for hash_value, original_value in hash_mapping.items():\n",
    "    print(f\"Hash: {hash_value} -> Original Value: {original_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51fa94b2-3e14-4fbd-a5da-f8f9021e7e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merkle Proof: ['0x3ac225168df54212a25c1c01fd35bebfea408fdac2e31ddd6f80a4bbf9a5f1cb']\n",
      "The value b is NOT in the Merkle tree.\n"
     ]
    }
   ],
   "source": [
    "from web3 import Web3\n",
    "from collections import deque\n",
    "\n",
    "# 创建一个 Web3 实例\n",
    "w3 = Web3()\n",
    "\n",
    "def hash_pair(left, right):\n",
    "    return w3.solidity_keccak(['bytes32', 'bytes32'], [left, right]).hex()\n",
    "\n",
    "def build_merkle_tree(leaves):\n",
    "    if not leaves:\n",
    "        raise ValueError(\"The list of leaves cannot be empty\")\n",
    "\n",
    "    # Hash the leaves using Web3's solidity_keccak and store the mappings\n",
    "    hashed_leaves = [(w3.solidity_keccak(['string'], [leaf]).hex(), leaf) if isinstance(leaf, str) else (leaf, leaf) for leaf in leaves]\n",
    "\n",
    "    # Use deque for efficient pop from left\n",
    "    current_level = deque(hashed_leaves)\n",
    "    \n",
    "    # Dictionary to store the mappings from hash to original values or node pairs\n",
    "    hash_mapping = {hashed: original for hashed, original in hashed_leaves}\n",
    "    proof_mapping = {}  # Dictionary to store proof nodes for each leaf\n",
    "\n",
    "    while len(current_level) > 1:\n",
    "        next_level = deque()\n",
    "        \n",
    "        while len(current_level) > 1:\n",
    "            left_hashed, left_value = current_level.popleft()\n",
    "            right_hashed, right_value = current_level.popleft()\n",
    "            parent_hash = hash_pair(left_hashed, right_hashed)\n",
    "            next_level.append((parent_hash, (left_value, right_value)))\n",
    "            hash_mapping[parent_hash] = (left_value, right_value)\n",
    "            \n",
    "            # Store proof for each child node\n",
    "            if left_hashed not in proof_mapping:\n",
    "                proof_mapping[left_hashed] = []\n",
    "            proof_mapping[left_hashed].append(right_hashed)\n",
    "            \n",
    "            if right_hashed not in proof_mapping:\n",
    "                proof_mapping[right_hashed] = []\n",
    "            proof_mapping[right_hashed].append(left_hashed)\n",
    "        \n",
    "        if current_level:  # If odd number of elements, carry the last element to the next level\n",
    "            next_level.append(current_level.popleft())\n",
    "        \n",
    "        current_level = next_level\n",
    "\n",
    "    # The root of the tree\n",
    "    root_hashed, root_value = current_level[0]\n",
    "    hash_mapping[root_hashed] = root_value\n",
    "\n",
    "    return hash_mapping, proof_mapping, root_hashed\n",
    "\n",
    "def get_merkle_proof(value, hash_mapping, proof_mapping):\n",
    "    if isinstance(value, str):\n",
    "        value_hash = w3.solidity_keccak(['string'], [value]).hex()\n",
    "    else:\n",
    "        value_hash = value\n",
    "    \n",
    "    proof = []\n",
    "    current_hash = value_hash\n",
    "    \n",
    "    while current_hash in proof_mapping:\n",
    "        siblings = proof_mapping[current_hash]\n",
    "        proof.extend(siblings)\n",
    "        \n",
    "        if len(siblings) == 1:  # If only one sibling, it means it's the last element in the level\n",
    "            sibling_hash = siblings[0]\n",
    "            current_hash = hash_pair(current_hash, sibling_hash)\n",
    "        else:\n",
    "            current_hash = hash_pair(current_hash, siblings[0])\n",
    "    \n",
    "    return proof\n",
    "\n",
    "def verify_merkle_proof(value, proof, root):\n",
    "    if isinstance(value, str):\n",
    "        value_hash = w3.solidity_keccak(['string'], [value]).hex()\n",
    "    else:\n",
    "        value_hash = value\n",
    "    \n",
    "    current_hash = value_hash\n",
    "    \n",
    "    for sibling_hash in proof:\n",
    "        if int(current_hash, 16) < int(sibling_hash, 16):\n",
    "            current_hash = hash_pair(current_hash, sibling_hash)\n",
    "        else:\n",
    "            current_hash = hash_pair(sibling_hash, current_hash)\n",
    "    \n",
    "    return current_hash == root\n",
    "\n",
    "# Example usage\n",
    "leaves = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "hash_mapping, proof_mapping, root = build_merkle_tree(leaves)\n",
    "\n",
    "# Value to verify\n",
    "value_to_verify = 'b'\n",
    "\n",
    "# Generate Merkle proof for the value\n",
    "proof = get_merkle_proof(value_to_verify, hash_mapping, proof_mapping)\n",
    "print(\"Merkle Proof:\", proof)\n",
    "\n",
    "# Verify the proof\n",
    "is_valid = verify_merkle_proof(value_to_verify, proof, root)\n",
    "if is_valid:\n",
    "    print(f\"The value {value_to_verify} is in the Merkle tree.\")\n",
    "else:\n",
    "    print(f\"The value {value_to_verify} is NOT in the Merkle tree.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1335273-e60c-40ce-8a46-c5a534c5dac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merkle Root: 8b2250fe623ab08574c76b8c5f73dff7f2a451cebf733f59e6527f4b25302e51381cf5c0471a7c9952bd8bb3a2156706debfa881aa4e463c8f73d968488da8b5\n",
      "Merkle Proof for 'b': ['333fcb4ee1aa7c115355ec66ceac917c8bfd815bf7587d325aec1864edd24e34d5abe2c6b1b5ee3face62fed78dbef802f2a85cb91d455a8f5249d330853cb3c', 'bdc6c31509183f56518d06ac8fd13ac5ff33e3d7b6597df2ada73d4758d2c9e024dd08942573ef8b3aebe2f7c3b32a2cd4d033234534c90c657223de75037f11', 'ee5ae70fd28c051cfc16a91b5076be924850525561f0bb4c61e4e180aa7c681f64f3659b567a9fd28987f7348b7b649a49c24f424730e83bc62bb433d7c2808f']\n",
      "The value 'b' is valid in the Merkle tree.\n"
     ]
    }
   ],
   "source": [
    "from hashlib import blake2b\n",
    "\n",
    "class Merkle:\n",
    "    H = blake2b\n",
    "\n",
    "    @staticmethod\n",
    "    def commit_(leafs):\n",
    "        assert(len(leafs) & (len(leafs)-1) == 0), \"length must be power of two\"\n",
    "        if len(leafs) == 1:\n",
    "            return leafs[0]\n",
    "        else:\n",
    "            return Merkle.H(Merkle.commit_(leafs[:len(leafs)//2]) + Merkle.commit_(leafs[len(leafs)//2:])).digest()\n",
    "\n",
    "    @staticmethod\n",
    "    def commit(data_array):\n",
    "        return Merkle.commit_([Merkle.H(bytes(da, 'utf-8')).digest() for da in data_array])\n",
    "    \n",
    "    @staticmethod\n",
    "    def open_(index, leafs):\n",
    "        assert(len(leafs) & (len(leafs)-1) == 0), \"length must be power of two\"\n",
    "        assert(0 <= index < len(leafs)), \"cannot open invalid index\"\n",
    "        if len(leafs) == 2:\n",
    "            return [leafs[1 - index]]\n",
    "        elif index < (len(leafs) / 2):\n",
    "            return Merkle.open_(index, leafs[:len(leafs)//2]) + [Merkle.commit_(leafs[len(leafs)//2:])]\n",
    "        else:\n",
    "            return Merkle.open_(index - len(leafs)//2, leafs[len(leafs)//2:]) + [Merkle.commit_(leafs[:len(leafs)//2])]\n",
    "\n",
    "    @staticmethod\n",
    "    def open(index, data_array):\n",
    "        return Merkle.open_(index, [Merkle.H(bytes(da, 'utf-8')).digest() for da in data_array])\n",
    "    \n",
    "    @staticmethod\n",
    "    def verify_(root, index, path, leaf):\n",
    "        assert(0 <= index < (1 << len(path))), \"cannot verify invalid index\"\n",
    "        if len(path) == 1:\n",
    "            if index == 0:\n",
    "                return root == Merkle.H(leaf + path[0]).digest()\n",
    "            else:\n",
    "                return root == Merkle.H(path[0] + leaf).digest()\n",
    "        else:\n",
    "            if index % 2 == 0:\n",
    "                return Merkle.verify_(root, index >> 1, path[1:], Merkle.H(leaf + path[0]).digest())\n",
    "            else:\n",
    "                return Merkle.verify_(root, index >> 1, path[1:], Merkle.H(path[0] + leaf).digest())\n",
    "\n",
    "    @staticmethod\n",
    "    def verify(root, index, path, data_element):\n",
    "        return Merkle.verify_(root, index, path, Merkle.H(bytes(data_element, 'utf-8')).digest())\n",
    "\n",
    "# Example usage\n",
    "data_array = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "\n",
    "# 1. Commit the Merkle Tree and get the root\n",
    "root = Merkle.commit(data_array)\n",
    "print(\"Merkle Root:\", root.hex())\n",
    "\n",
    "# 2. Open a leaf to get its Merkle proof\n",
    "index_to_open = 1  # Index of 'b'\n",
    "proof = Merkle.open(index_to_open, data_array)\n",
    "print(\"Merkle Proof for 'b':\", [p.hex() for p in proof])\n",
    "\n",
    "# 3. Verify the proof\n",
    "is_valid = Merkle.verify(root, index_to_open, proof, 'b')\n",
    "print(f\"The value 'b' is {'valid' if is_valid else 'not valid'} in the Merkle tree.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bf7947d-6881-42eb-ad35-21630b81e9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merkle Root: 8b2250fe623ab08574c76b8c5f73dff7f2a451cebf733f59e6527f4b25302e51381cf5c0471a7c9952bd8bb3a2156706debfa881aa4e463c8f73d968488da8b5\n",
      "\n",
      "Merkle Tree Storage:\n",
      "Node: 7027cee7ccfd7ba4ae5e281acfc6ad80e5dd2bc6300993c949c047979b9cccd50b321980da9325ea282773f606eb61509b791a31815f8057dd3535a80d071bf0 -> Left: 333fcb4ee1aa7c115355ec66ceac917c8bfd815bf7587d325aec1864edd24e34d5abe2c6b1b5ee3face62fed78dbef802f2a85cb91d455a8f5249d330853cb3c, Right: c029c24b2c89db037fbf8b04930569fd8422f7c0d62f36c8dae35d03332139e546a1126f6c75be43685598f48cefff1d05a3c74d804fcd5c0a53734cfb0bb862\n",
      "Node: bdc6c31509183f56518d06ac8fd13ac5ff33e3d7b6597df2ada73d4758d2c9e024dd08942573ef8b3aebe2f7c3b32a2cd4d033234534c90c657223de75037f11 -> Left: 437f3ef49ef1381c1dcb18dbc11ee6efba9b74591da881fb9a7895aa70f140563cfdd2b308beb05211ead01871c8de33efc566fcfea887377129d2a1aeadfd3e, Right: 0fddfe69251fd8b811a37bb45f8ef0c8485d3e60d84361d15701a5603b30cfcd572bd0bccd1e108dd697c7c53c492c188a42029b1b8a47c9ecf9ac311fc0a3e8\n",
      "Node: 57148d9356c76fde4d7bfa73ff2ec024caec694252497ff1a0fb926085bbfda6063f0fcb759db2801851073709b79d5b38c0585a2d8c8e646152bf71c4e57a20 -> Left: 7027cee7ccfd7ba4ae5e281acfc6ad80e5dd2bc6300993c949c047979b9cccd50b321980da9325ea282773f606eb61509b791a31815f8057dd3535a80d071bf0, Right: bdc6c31509183f56518d06ac8fd13ac5ff33e3d7b6597df2ada73d4758d2c9e024dd08942573ef8b3aebe2f7c3b32a2cd4d033234534c90c657223de75037f11\n",
      "Node: 2f1610922bb2a8e271a040c3f28c7ad140fbfb8fdb1e0b639ad882b773c316bd35d456085e20026432a87195835ea9218b67e7decce4b053599c3a0cb9350adb -> Left: faaa8a2965e6e1c5448eb4e6e647683333635103abcbf41ab013f8cf5e33df43ef2f9574042959f86f95ecca8cef9ca7d631ff3bd0bb213fa2a6769a319cfb4d, Right: c6b1bb497ac41e42292c35b6c26acfd3b3463d0fe542ce844fedbf86097b3fe43ab13763ee0c61048e1c1fb8bd6b087cacc4fce8da5dad147c86a9cf21a64952\n",
      "Node: b833073330fcbfb86508350c660b1dc72ddb62e2b7f0beeba9fb400ed8b78c99d2db1291db672c6730246aa73c699612b6f5ff64e96c95f71432438e3e7fd86d -> Left: dd04be7b0cbc203b88bb81d5ed272ad6a810148c02ade289c1a92415f6287b70b9bcb7b4d5760232317bcae0b96c975fdcdb52d20e727bf655c3866af95a65a1, Right: 0d3f1f2ea78fb43de7bb1aac02eceb9ca9ff36caea7eed5add3d3e9fa9458c0181df9e3d9aaa57c28d0fd13a2550e49ba66e5f7a60efe5ea7bcbf76d0fb740e5\n",
      "Node: ee5ae70fd28c051cfc16a91b5076be924850525561f0bb4c61e4e180aa7c681f64f3659b567a9fd28987f7348b7b649a49c24f424730e83bc62bb433d7c2808f -> Left: 2f1610922bb2a8e271a040c3f28c7ad140fbfb8fdb1e0b639ad882b773c316bd35d456085e20026432a87195835ea9218b67e7decce4b053599c3a0cb9350adb, Right: b833073330fcbfb86508350c660b1dc72ddb62e2b7f0beeba9fb400ed8b78c99d2db1291db672c6730246aa73c699612b6f5ff64e96c95f71432438e3e7fd86d\n",
      "Node: 8b2250fe623ab08574c76b8c5f73dff7f2a451cebf733f59e6527f4b25302e51381cf5c0471a7c9952bd8bb3a2156706debfa881aa4e463c8f73d968488da8b5 -> Left: 57148d9356c76fde4d7bfa73ff2ec024caec694252497ff1a0fb926085bbfda6063f0fcb759db2801851073709b79d5b38c0585a2d8c8e646152bf71c4e57a20, Right: ee5ae70fd28c051cfc16a91b5076be924850525561f0bb4c61e4e180aa7c681f64f3659b567a9fd28987f7348b7b649a49c24f424730e83bc62bb433d7c2808f\n",
      "\n",
      "Merkle Proof for 'b': ['333fcb4ee1aa7c115355ec66ceac917c8bfd815bf7587d325aec1864edd24e34d5abe2c6b1b5ee3face62fed78dbef802f2a85cb91d455a8f5249d330853cb3c', 'bdc6c31509183f56518d06ac8fd13ac5ff33e3d7b6597df2ada73d4758d2c9e024dd08942573ef8b3aebe2f7c3b32a2cd4d033234534c90c657223de75037f11', 'ee5ae70fd28c051cfc16a91b5076be924850525561f0bb4c61e4e180aa7c681f64f3659b567a9fd28987f7348b7b649a49c24f424730e83bc62bb433d7c2808f']\n",
      "\n",
      "The value 'b' is valid in the Merkle tree.\n"
     ]
    }
   ],
   "source": [
    "from hashlib import blake2b\n",
    "\n",
    "class Merkle:\n",
    "    H = blake2b\n",
    "\n",
    "    @staticmethod\n",
    "    def hash_leaf(leaf):\n",
    "        return Merkle.H(bytes(leaf, 'utf-8')).digest()\n",
    "    \n",
    "    @staticmethod\n",
    "    def hash_node(left, right):\n",
    "        return Merkle.H(left + right).digest()\n",
    "\n",
    "    @staticmethod\n",
    "    def commit_(leafs, storage):\n",
    "        assert len(leafs) & (len(leafs) - 1) == 0, \"length must be power of two\"\n",
    "        if len(leafs) == 1:\n",
    "            return leafs[0]\n",
    "        else:\n",
    "            left_hash = Merkle.commit_(leafs[:len(leafs)//2], storage)\n",
    "            right_hash = Merkle.commit_(leafs[len(leafs)//2:], storage)\n",
    "            combined_hash = Merkle.hash_node(left_hash, right_hash)\n",
    "            storage[combined_hash] = (left_hash, right_hash)\n",
    "            return combined_hash\n",
    "\n",
    "    @staticmethod\n",
    "    def commit(data_array):\n",
    "        hashed_leaves = [Merkle.hash_leaf(leaf) for leaf in data_array]\n",
    "        storage = {}\n",
    "        root = Merkle.commit_(hashed_leaves, storage)\n",
    "        return root, storage\n",
    "    \n",
    "    @staticmethod\n",
    "    def open_(index, leafs):\n",
    "        assert len(leafs) & (len(leafs) - 1) == 0, \"length must be power of two\"\n",
    "        assert 0 <= index < len(leafs), \"cannot open invalid index\"\n",
    "        if len(leafs) == 2:\n",
    "            return [leafs[1 - index]]\n",
    "        elif index < (len(leafs) / 2):\n",
    "            return Merkle.open_(index, leafs[:len(leafs)//2]) + [Merkle.commit_(leafs[len(leafs)//2:], {})]\n",
    "        else:\n",
    "            return Merkle.open_(index - len(leafs)//2, leafs[len(leafs)//2:]) + [Merkle.commit_(leafs[:len(leafs)//2], {})]\n",
    "\n",
    "    @staticmethod\n",
    "    def open(index, data_array):\n",
    "        return Merkle.open_(index, [Merkle.hash_leaf(leaf) for leaf in data_array])\n",
    "    \n",
    "    @staticmethod\n",
    "    def verify_(root, index, path, leaf):\n",
    "        assert 0 <= index < (1 << len(path)), \"cannot verify invalid index\"\n",
    "        if len(path) == 1:\n",
    "            if index == 0:\n",
    "                return root == Merkle.hash_node(leaf, path[0])\n",
    "            else:\n",
    "                return root == Merkle.hash_node(path[0], leaf)\n",
    "        else:\n",
    "            if index % 2 == 0:\n",
    "                return Merkle.verify_(root, index >> 1, path[1:], Merkle.hash_node(leaf, path[0]))\n",
    "            else:\n",
    "                return Merkle.verify_(root, index >> 1, path[1:], Merkle.hash_node(path[0], leaf))\n",
    "\n",
    "    @staticmethod\n",
    "    def verify(root, index, path, data_element):\n",
    "        return Merkle.verify_(root, index, path, Merkle.hash_leaf(data_element))\n",
    "\n",
    "# Example usage\n",
    "data_array = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "\n",
    "# 1. Commit the Merkle Tree and get the root\n",
    "root, storage = Merkle.commit(data_array)\n",
    "print(\"Merkle Root:\", root.hex())\n",
    "\n",
    "# Print the storage to see the tree structure\n",
    "print(\"\\nMerkle Tree Storage:\")\n",
    "for k, v in storage.items():\n",
    "    if isinstance(v, tuple):\n",
    "        left_hash, right_hash = v\n",
    "        print(f\"Node: {k.hex()} -> Left: {left_hash.hex()}, Right: {right_hash.hex()}\")\n",
    "    else:\n",
    "        print(f\"Leaf: {k.hex()} -> Value: {v}\")\n",
    "\n",
    "# 2. Open a leaf to get its Merkle proof\n",
    "index_to_open = 1  # Index of 'b'\n",
    "proof = Merkle.open(index_to_open, data_array)\n",
    "print(\"\\nMerkle Proof for 'b':\", [p.hex() for p in proof])\n",
    "\n",
    "# 3. Verify the proof\n",
    "is_valid = Merkle.verify(root, index_to_open, proof, 'b')\n",
    "print(f\"\\nThe value 'b' is {'valid' if is_valid else 'not valid'} in the Merkle tree.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7db7ebd4-5e0e-4ed4-a779-22a748bddeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merkle Root: 8b2250fe623ab08574c76b8c5f73dff7f2a451cebf733f59e6527f4b25302e51381cf5c0471a7c9952bd8bb3a2156706debfa881aa4e463c8f73d968488da8b5\n",
      "\n",
      "Merkle Tree Storage:\n",
      "Node: 7027cee7ccfd7ba4ae5e281acfc6ad80e5dd2bc6300993c949c047979b9cccd50b321980da9325ea282773f606eb61509b791a31815f8057dd3535a80d071bf0 -> Left: 333fcb4ee1aa7c115355ec66ceac917c8bfd815bf7587d325aec1864edd24e34d5abe2c6b1b5ee3face62fed78dbef802f2a85cb91d455a8f5249d330853cb3c, Right: c029c24b2c89db037fbf8b04930569fd8422f7c0d62f36c8dae35d03332139e546a1126f6c75be43685598f48cefff1d05a3c74d804fcd5c0a53734cfb0bb862\n",
      "Node: bdc6c31509183f56518d06ac8fd13ac5ff33e3d7b6597df2ada73d4758d2c9e024dd08942573ef8b3aebe2f7c3b32a2cd4d033234534c90c657223de75037f11 -> Left: 437f3ef49ef1381c1dcb18dbc11ee6efba9b74591da881fb9a7895aa70f140563cfdd2b308beb05211ead01871c8de33efc566fcfea887377129d2a1aeadfd3e, Right: 0fddfe69251fd8b811a37bb45f8ef0c8485d3e60d84361d15701a5603b30cfcd572bd0bccd1e108dd697c7c53c492c188a42029b1b8a47c9ecf9ac311fc0a3e8\n",
      "Node: 57148d9356c76fde4d7bfa73ff2ec024caec694252497ff1a0fb926085bbfda6063f0fcb759db2801851073709b79d5b38c0585a2d8c8e646152bf71c4e57a20 -> Left: 7027cee7ccfd7ba4ae5e281acfc6ad80e5dd2bc6300993c949c047979b9cccd50b321980da9325ea282773f606eb61509b791a31815f8057dd3535a80d071bf0, Right: bdc6c31509183f56518d06ac8fd13ac5ff33e3d7b6597df2ada73d4758d2c9e024dd08942573ef8b3aebe2f7c3b32a2cd4d033234534c90c657223de75037f11\n",
      "Node: 2f1610922bb2a8e271a040c3f28c7ad140fbfb8fdb1e0b639ad882b773c316bd35d456085e20026432a87195835ea9218b67e7decce4b053599c3a0cb9350adb -> Left: faaa8a2965e6e1c5448eb4e6e647683333635103abcbf41ab013f8cf5e33df43ef2f9574042959f86f95ecca8cef9ca7d631ff3bd0bb213fa2a6769a319cfb4d, Right: c6b1bb497ac41e42292c35b6c26acfd3b3463d0fe542ce844fedbf86097b3fe43ab13763ee0c61048e1c1fb8bd6b087cacc4fce8da5dad147c86a9cf21a64952\n",
      "Node: b833073330fcbfb86508350c660b1dc72ddb62e2b7f0beeba9fb400ed8b78c99d2db1291db672c6730246aa73c699612b6f5ff64e96c95f71432438e3e7fd86d -> Left: dd04be7b0cbc203b88bb81d5ed272ad6a810148c02ade289c1a92415f6287b70b9bcb7b4d5760232317bcae0b96c975fdcdb52d20e727bf655c3866af95a65a1, Right: 0d3f1f2ea78fb43de7bb1aac02eceb9ca9ff36caea7eed5add3d3e9fa9458c0181df9e3d9aaa57c28d0fd13a2550e49ba66e5f7a60efe5ea7bcbf76d0fb740e5\n",
      "Node: ee5ae70fd28c051cfc16a91b5076be924850525561f0bb4c61e4e180aa7c681f64f3659b567a9fd28987f7348b7b649a49c24f424730e83bc62bb433d7c2808f -> Left: 2f1610922bb2a8e271a040c3f28c7ad140fbfb8fdb1e0b639ad882b773c316bd35d456085e20026432a87195835ea9218b67e7decce4b053599c3a0cb9350adb, Right: b833073330fcbfb86508350c660b1dc72ddb62e2b7f0beeba9fb400ed8b78c99d2db1291db672c6730246aa73c699612b6f5ff64e96c95f71432438e3e7fd86d\n",
      "Node: 8b2250fe623ab08574c76b8c5f73dff7f2a451cebf733f59e6527f4b25302e51381cf5c0471a7c9952bd8bb3a2156706debfa881aa4e463c8f73d968488da8b5 -> Left: 57148d9356c76fde4d7bfa73ff2ec024caec694252497ff1a0fb926085bbfda6063f0fcb759db2801851073709b79d5b38c0585a2d8c8e646152bf71c4e57a20, Right: ee5ae70fd28c051cfc16a91b5076be924850525561f0bb4c61e4e180aa7c681f64f3659b567a9fd28987f7348b7b649a49c24f424730e83bc62bb433d7c2808f\n",
      "\n",
      "Merkle Tree Hash Mapping:\n",
      "Hash: 333fcb4ee1aa7c115355ec66ceac917c8bfd815bf7587d325aec1864edd24e34d5abe2c6b1b5ee3face62fed78dbef802f2a85cb91d455a8f5249d330853cb3c -> Original Value: a\n",
      "Hash: c029c24b2c89db037fbf8b04930569fd8422f7c0d62f36c8dae35d03332139e546a1126f6c75be43685598f48cefff1d05a3c74d804fcd5c0a53734cfb0bb862 -> Original Value: b\n",
      "Hash: 437f3ef49ef1381c1dcb18dbc11ee6efba9b74591da881fb9a7895aa70f140563cfdd2b308beb05211ead01871c8de33efc566fcfea887377129d2a1aeadfd3e -> Original Value: c\n",
      "Hash: 0fddfe69251fd8b811a37bb45f8ef0c8485d3e60d84361d15701a5603b30cfcd572bd0bccd1e108dd697c7c53c492c188a42029b1b8a47c9ecf9ac311fc0a3e8 -> Original Value: d\n",
      "Hash: faaa8a2965e6e1c5448eb4e6e647683333635103abcbf41ab013f8cf5e33df43ef2f9574042959f86f95ecca8cef9ca7d631ff3bd0bb213fa2a6769a319cfb4d -> Original Value: e\n",
      "Hash: c6b1bb497ac41e42292c35b6c26acfd3b3463d0fe542ce844fedbf86097b3fe43ab13763ee0c61048e1c1fb8bd6b087cacc4fce8da5dad147c86a9cf21a64952 -> Original Value: f\n",
      "Hash: dd04be7b0cbc203b88bb81d5ed272ad6a810148c02ade289c1a92415f6287b70b9bcb7b4d5760232317bcae0b96c975fdcdb52d20e727bf655c3866af95a65a1 -> Original Value: g\n",
      "Hash: 0d3f1f2ea78fb43de7bb1aac02eceb9ca9ff36caea7eed5add3d3e9fa9458c0181df9e3d9aaa57c28d0fd13a2550e49ba66e5f7a60efe5ea7bcbf76d0fb740e5 -> Original Value: h\n",
      "Hash: 7027cee7ccfd7ba4ae5e281acfc6ad80e5dd2bc6300993c949c047979b9cccd50b321980da9325ea282773f606eb61509b791a31815f8057dd3535a80d071bf0 -> Original Value: ('a', 'b')\n",
      "Hash: bdc6c31509183f56518d06ac8fd13ac5ff33e3d7b6597df2ada73d4758d2c9e024dd08942573ef8b3aebe2f7c3b32a2cd4d033234534c90c657223de75037f11 -> Original Value: ('c', 'd')\n",
      "Hash: 57148d9356c76fde4d7bfa73ff2ec024caec694252497ff1a0fb926085bbfda6063f0fcb759db2801851073709b79d5b38c0585a2d8c8e646152bf71c4e57a20 -> Original Value: (('a', 'b'), ('c', 'd'))\n",
      "Hash: 2f1610922bb2a8e271a040c3f28c7ad140fbfb8fdb1e0b639ad882b773c316bd35d456085e20026432a87195835ea9218b67e7decce4b053599c3a0cb9350adb -> Original Value: ('e', 'f')\n",
      "Hash: b833073330fcbfb86508350c660b1dc72ddb62e2b7f0beeba9fb400ed8b78c99d2db1291db672c6730246aa73c699612b6f5ff64e96c95f71432438e3e7fd86d -> Original Value: ('g', 'h')\n",
      "Hash: ee5ae70fd28c051cfc16a91b5076be924850525561f0bb4c61e4e180aa7c681f64f3659b567a9fd28987f7348b7b649a49c24f424730e83bc62bb433d7c2808f -> Original Value: (('e', 'f'), ('g', 'h'))\n",
      "Hash: 8b2250fe623ab08574c76b8c5f73dff7f2a451cebf733f59e6527f4b25302e51381cf5c0471a7c9952bd8bb3a2156706debfa881aa4e463c8f73d968488da8b5 -> Original Value: ((('a', 'b'), ('c', 'd')), (('e', 'f'), ('g', 'h')))\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "b'C\\x7f>\\xf4\\x9e\\xf18\\x1c\\x1d\\xcb\\x18\\xdb\\xc1\\x1e\\xe6\\xef\\xba\\x9btY\\x1d\\xa8\\x81\\xfb\\x9ax\\x95\\xaap\\xf1@V<\\xfd\\xd2\\xb3\\x08\\xbe\\xb0R\\x11\\xea\\xd0\\x18q\\xc8\\xde3\\xef\\xc5f\\xfc\\xfe\\xa8\\x877q)\\xd2\\xa1\\xae\\xad\\xfd>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16644\\1543390969.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;31m# 2. Open a leaf to get its Merkle proof\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[0mindex_to_open\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# Index of 'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m \u001b[0mproof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMerkle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_to_open\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nMerkle Proof for 'b':\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproof\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16644\\1543390969.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(index, data_array)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mMerkle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mMerkle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhash_leaf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleaf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mleaf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_array\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16644\\1543390969.py\u001b[0m in \u001b[0;36mopen_\u001b[1;34m(index, leafs)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mMerkle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleafs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mMerkle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mMerkle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleafs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mMerkle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16644\\1543390969.py\u001b[0m in \u001b[0;36mopen_\u001b[1;34m(index, leafs)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mMerkle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleafs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mMerkle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mMerkle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleafs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mMerkle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleafs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16644\\1543390969.py\u001b[0m in \u001b[0;36mcommit_\u001b[1;34m(leafs, storage, hash_to_original)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mstorage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcombined_hash\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mleft_hash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_hash\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m# Store original values for intermediate nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mhash_to_original\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcombined_hash\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhash_to_original\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mleft_hash\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhash_to_original\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mright_hash\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcombined_hash\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: b'C\\x7f>\\xf4\\x9e\\xf18\\x1c\\x1d\\xcb\\x18\\xdb\\xc1\\x1e\\xe6\\xef\\xba\\x9btY\\x1d\\xa8\\x81\\xfb\\x9ax\\x95\\xaap\\xf1@V<\\xfd\\xd2\\xb3\\x08\\xbe\\xb0R\\x11\\xea\\xd0\\x18q\\xc8\\xde3\\xef\\xc5f\\xfc\\xfe\\xa8\\x877q)\\xd2\\xa1\\xae\\xad\\xfd>'"
     ]
    }
   ],
   "source": [
    "from hashlib import blake2b\n",
    "\n",
    "class Merkle:\n",
    "    H = blake2b\n",
    "\n",
    "    @staticmethod\n",
    "    def hash_leaf(leaf):\n",
    "        return Merkle.H(bytes(leaf, 'utf-8')).digest()\n",
    "    \n",
    "    @staticmethod\n",
    "    def hash_node(left, right):\n",
    "        return Merkle.H(left + right).digest()\n",
    "\n",
    "    @staticmethod\n",
    "    def commit_(leafs, storage, hash_to_original):\n",
    "        assert len(leafs) & (len(leafs) - 1) == 0, \"length must be power of two\"\n",
    "        if len(leafs) == 1:\n",
    "            return leafs[0]\n",
    "        else:\n",
    "            left_hash = Merkle.commit_(leafs[:len(leafs)//2], storage, hash_to_original)\n",
    "            right_hash = Merkle.commit_(leafs[len(leafs)//2:], storage, hash_to_original)\n",
    "            combined_hash = Merkle.hash_node(left_hash, right_hash)\n",
    "            storage[combined_hash] = (left_hash, right_hash)\n",
    "            # Store original values for intermediate nodes\n",
    "            hash_to_original[combined_hash] = (hash_to_original[left_hash], hash_to_original[right_hash])\n",
    "            return combined_hash\n",
    "\n",
    "    @staticmethod\n",
    "    def commit(data_array):\n",
    "        hashed_leaves = [Merkle.hash_leaf(leaf) for leaf in data_array]\n",
    "        storage = {}\n",
    "        hash_to_original = {Merkle.hash_leaf(leaf): leaf for leaf in data_array}\n",
    "        root = Merkle.commit_(hashed_leaves, storage, hash_to_original)\n",
    "        return root, storage, hash_to_original\n",
    "    \n",
    "    @staticmethod\n",
    "    def open_(index, leafs):\n",
    "        assert len(leafs) & (len(leafs) - 1) == 0, \"length must be power of two\"\n",
    "        assert 0 <= index < len(leafs), \"cannot open invalid index\"\n",
    "        if len(leafs) == 2:\n",
    "            return [leafs[1 - index]]\n",
    "        elif index < (len(leafs) / 2):\n",
    "            return Merkle.open_(index, leafs[:len(leafs)//2]) + [Merkle.commit_(leafs[len(leafs)//2:], {}, {})]\n",
    "        else:\n",
    "            return Merkle.open_(index - len(leafs)//2, leafs[len(leafs)//2:]) + [Merkle.commit_(leafs[:len(leafs)//2], {}, {})]\n",
    "\n",
    "    @staticmethod\n",
    "    def open(index, data_array):\n",
    "        return Merkle.open_(index, [Merkle.hash_leaf(leaf) for leaf in data_array])\n",
    "    \n",
    "    @staticmethod\n",
    "    def verify_(root, index, path, leaf):\n",
    "        assert 0 <= index < (1 << len(path)), \"cannot verify invalid index\"\n",
    "        if len(path) == 1:\n",
    "            if index == 0:\n",
    "                return root == Merkle.hash_node(leaf, path[0])\n",
    "            else:\n",
    "                return root == Merkle.hash_node(path[0], leaf)\n",
    "        else:\n",
    "            if index % 2 == 0:\n",
    "                return Merkle.verify_(root, index >> 1, path[1:], Merkle.hash_node(leaf, path[0]))\n",
    "            else:\n",
    "                return Merkle.verify_(root, index >> 1, path[1:], Merkle.hash_node(path[0], leaf))\n",
    "\n",
    "    @staticmethod\n",
    "    def verify(root, index, path, data_element):\n",
    "        return Merkle.verify_(root, index, path, Merkle.hash_leaf(data_element))\n",
    "\n",
    "# Example usage\n",
    "data_array = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "\n",
    "# 1. Commit the Merkle Tree and get the root\n",
    "root, storage, hash_to_original = Merkle.commit(data_array)\n",
    "print(\"Merkle Root:\", root.hex())\n",
    "\n",
    "# Print the storage to see the tree structure\n",
    "print(\"\\nMerkle Tree Storage:\")\n",
    "for k, v in storage.items():\n",
    "    if isinstance(v, tuple):\n",
    "        left_hash, right_hash = v\n",
    "        print(f\"Node: {k.hex()} -> Left: {left_hash.hex()}, Right: {right_hash.hex()}\")\n",
    "    else:\n",
    "        print(f\"Leaf: {k.hex()} -> Value: {v}\")\n",
    "\n",
    "# Print the hash to original value mapping\n",
    "print(\"\\nMerkle Tree Hash Mapping:\")\n",
    "for k, v in hash_to_original.items():\n",
    "    print(f\"Hash: {k.hex()} -> Original Value: {v}\")\n",
    "\n",
    "# 2. Open a leaf to get its Merkle proof\n",
    "index_to_open = 1  # Index of 'b'\n",
    "proof = Merkle.open(index_to_open, data_array)\n",
    "print(\"\\nMerkle Proof for 'b':\", [p.hex() for p in proof])\n",
    "\n",
    "# 3. Verify the proof\n",
    "is_valid = Merkle.verify(root, index_to_open, proof, 'b')\n",
    "print(f\"\\nThe value 'b' is {'valid' if is_valid else 'not valid'} in the Merkle tree.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ef3d547-3063-4331-99a2-dd0a612d72c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web3 import Web3\n",
    "from collections import deque\n",
    "\n",
    "# 創建一個 Web3 實例\n",
    "w3 = Web3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5fc6e6-1f3a-4c16-91a9-25a6e9faa56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merkle Root: 0xcd07272f4955ddcfdac38ff36dff9d3e4353498923679ab548ba87e34648e4a3\n",
      "\n",
      "Merkle Tree Hash Mapping:\n",
      "Hash: 0x3ac225168df54212a25c1c01fd35bebfea408fdac2e31ddd6f80a4bbf9a5f1cb -> Original Value: a\n",
      "Hash: 0xb5553de315e0edf504d9150af82dafa5c4667fa618ed0a6f19c69b41166c5510 -> Original Value: b\n",
      "Hash: 0x0b42b6393c1f53060fe3ddbfcd7aadcca894465a5a438f69c87d790b2299b9b2 -> Original Value: c\n",
      "Hash: 0xf1918e8562236eb17adc8502332f4c9c82bc14e19bfc0aa10ab674ff75b3d2f3 -> Original Value: d\n",
      "Hash: 0xa8982c89d80987fb9a510e25981ee9170206be21af3c8e0eb312ef1d3382e761 -> Original Value: e\n",
      "Hash: 0xd1e8aeb79500496ef3dc2e57ba746a8315d048b7a664a2bf948db4fa91960483 -> Original Value: f\n",
      "Hash: 0x14bcc435f49d130d189737f9762feb25c44ef5b886bef833e31a702af6be4748 -> Original Value: g\n",
      "Hash: 0xa766932420cc6e9072394bef2c036ad8972c44696fee29397bd5e2c06001f615 -> Original Value: h\n",
      "Hash: 0x805b21d846b189efaeb0377d6bb0d201b3872a363e607c25088f025b0c6ae1f8 -> Original Value: ('a', 'b')\n",
      "Hash: 0xd253a52d4cb00de2895e85f2529e2976e6aaaa5c18106b68ab66813e14415669 -> Original Value: ('c', 'd')\n",
      "Hash: 0x68203f90e9d07dc5859259d7536e87a6ba9d345f2552b5b9de2999ddce9ce1bf -> Original Value: (('a', 'b'), ('c', 'd'))\n",
      "Hash: 0xf0b49bb4b0d9396e0315755ceafaa280707b32e75e6c9053f5cdf2679dcd5c6a -> Original Value: ('e', 'f')\n",
      "Hash: 0xe18a5c2ee5202ecdefed683f03145b1343304dbed01aecb94032b7f801844f0a -> Original Value: ('g', 'h')\n",
      "Hash: 0xf313fc9eb1c4864b1b8e78296656fb7831cc0ed46361bf3452db1c4cec430050 -> Original Value: (('e', 'f'), ('g', 'h'))\n",
      "Hash: 0xcd07272f4955ddcfdac38ff36dff9d3e4353498923679ab548ba87e34648e4a3 -> Original Value: ((('a', 'b'), ('c', 'd')), (('e', 'f'), ('g', 'h')))\n",
      "\n",
      "Merkle Proof for 'b': ['0x3ac225168df54212a25c1c01fd35bebfea408fdac2e31ddd6f80a4bbf9a5f1cb', '0xd253a52d4cb00de2895e85f2529e2976e6aaaa5c18106b68ab66813e14415669', '0xf313fc9eb1c4864b1b8e78296656fb7831cc0ed46361bf3452db1c4cec430050']\n",
      "\n",
      "The value 'b' is valid in the Merkle tree.\n"
     ]
    }
   ],
   "source": [
    "class Merkle:\n",
    "    @staticmethod\n",
    "    def hash_leaf(leaf):\n",
    "        return w3.solidity_keccak(['string'], [leaf]).hex()\n",
    "    \n",
    "    @staticmethod\n",
    "    def hash_node(left, right):\n",
    "        return w3.solidity_keccak(['bytes32', 'bytes32'], [left, right]).hex()\n",
    "\n",
    "    @staticmethod\n",
    "    def commit_(leafs, hash_to_original):\n",
    "        assert len(leafs) & (len(leafs) - 1) == 0, \"length must be power of two\"\n",
    "        if len(leafs) == 1:\n",
    "            return leafs[0]\n",
    "        else:\n",
    "            left_hash = Merkle.commit_(leafs[:len(leafs)//2], hash_to_original)\n",
    "            right_hash = Merkle.commit_(leafs[len(leafs)//2:], hash_to_original)\n",
    "            combined_hash = Merkle.hash_node(left_hash, right_hash)\n",
    "            \n",
    "            # Store original values for intermediate nodes, ensure the mapping exists\n",
    "            hash_to_original.setdefault(left_hash, left_hash)\n",
    "            hash_to_original.setdefault(right_hash, right_hash)\n",
    "            hash_to_original[combined_hash] = (hash_to_original[left_hash], hash_to_original[right_hash])\n",
    "            return combined_hash\n",
    "\n",
    "    @staticmethod\n",
    "    def commit(data_array):\n",
    "        hashed_leaves = [Merkle.hash_leaf(leaf) for leaf in data_array]\n",
    "        hash_to_original = {Merkle.hash_leaf(leaf): leaf for leaf in data_array}\n",
    "        root = Merkle.commit_(hashed_leaves, hash_to_original)\n",
    "        return root, hash_to_original\n",
    "    \n",
    "    @staticmethod\n",
    "    def open_(index, leafs):\n",
    "        assert len(leafs) & (len(leafs) - 1) == 0, \"length must be power of two\"\n",
    "        assert 0 <= index < len(leafs), \"cannot open invalid index\"\n",
    "        if len(leafs) == 2:\n",
    "            return [leafs[1 - index]]\n",
    "        elif index < (len(leafs) / 2):\n",
    "            return Merkle.open_(index, leafs[:len(leafs)//2]) + [Merkle.commit_(leafs[len(leafs)//2:], {})]\n",
    "        else:\n",
    "            return Merkle.open_(index - len(leafs)//2, leafs[len(leafs)//2:]) + [Merkle.commit_(leafs[:len(leafs)//2], {})]\n",
    "\n",
    "    @staticmethod\n",
    "    def open(index, data_array):\n",
    "        return Merkle.open_(index, [Merkle.hash_leaf(leaf) for leaf in data_array])\n",
    "    \n",
    "    @staticmethod\n",
    "    def verify_(root, index, path, leaf):\n",
    "        assert 0 <= index < (1 << len(path)), \"cannot verify invalid index\"\n",
    "        if len(path) == 1:\n",
    "            if index == 0:\n",
    "                return root == Merkle.hash_node(leaf, path[0])\n",
    "            else:\n",
    "                return root == Merkle.hash_node(path[0], leaf)\n",
    "        else:\n",
    "            if index % 2 == 0:\n",
    "                return Merkle.verify_(root, index >> 1, path[1:], Merkle.hash_node(leaf, path[0]))\n",
    "            else:\n",
    "                return Merkle.verify_(root, index >> 1, path[1:], Merkle.hash_node(path[0], leaf))\n",
    "\n",
    "    @staticmethod\n",
    "    def verify(root, index, path, data_element):\n",
    "        return Merkle.verify_(root, index, path, Merkle.hash_leaf(data_element))\n",
    "\n",
    "# Example usage\n",
    "data_array = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "\n",
    "# 1. Commit the Merkle Tree and get the root\n",
    "root, hash_to_original = Merkle.commit(data_array)\n",
    "print(\"Merkle Root:\", root)\n",
    "\n",
    "# Print the hash to original value mapping\n",
    "print(\"\\nMerkle Tree Hash Mapping:\")\n",
    "for k, v in hash_to_original.items():\n",
    "    print(f\"Hash: {k} -> Original Value: {v}\")\n",
    "\n",
    "# 2. Open a leaf to get its Merkle proof\n",
    "index_to_open = 1  # Index of 'b'\n",
    "proof = Merkle.open(index_to_open, data_array)\n",
    "print(\"\\nMerkle Proof for 'b':\", [p for p in proof])\n",
    "\n",
    "# 3. Verify the proof\n",
    "is_valid = Merkle.verify(root, index_to_open, proof, 'b')\n",
    "print(f\"\\nThe value 'b' is {'valid' if is_valid else 'not valid'} in the Merkle tree.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181eeaf-1e4e-4b5b-9222-cbf0f529d8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7ecd65-2139-45f0-b152-256343c054ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import blake2b\n",
    "\n",
    "class Merkle:\n",
    "    H = blake2b\n",
    "\n",
    "    @staticmethod\n",
    "    def hash_leaf(leaf):\n",
    "        return w3.solidity_keccak(['string'], [leaf]).hex()\n",
    "    \n",
    "    @staticmethod\n",
    "    def hash_node(left, right):\n",
    "        return w3.solidity_keccak(['bytes32', 'bytes32'], [left, right]).hex()\n",
    "\n",
    "    @staticmethod\n",
    "    def commit_(leafs, storage, hash_to_original):\n",
    "        assert len(leafs) & (len(leafs) - 1) == 0, \"length must be power of two\"\n",
    "        if len(leafs) == 1:\n",
    "            return leafs[0]\n",
    "        else:\n",
    "            left_hash = Merkle.commit_(leafs[:len(leafs)//2], storage, hash_to_original)\n",
    "            right_hash = Merkle.commit_(leafs[len(leafs)//2:], storage, hash_to_original)\n",
    "            combined_hash = Merkle.hash_node(left_hash, right_hash)\n",
    "            storage[combined_hash] = (left_hash, right_hash)\n",
    "            # Store original values for intermediate nodes, ensure the mapping exists\n",
    "            hash_to_original.setdefault(left_hash, left_hash)\n",
    "            hash_to_original.setdefault(right_hash, right_hash)\n",
    "            hash_to_original[combined_hash] = (hash_to_original[left_hash], hash_to_original[right_hash])\n",
    "            return combined_hash\n",
    "\n",
    "    @staticmethod\n",
    "    def commit(data_array):\n",
    "        hashed_leaves = [Merkle.hash_leaf(leaf) for leaf in data_array]\n",
    "        storage = {}\n",
    "        hash_to_original = {Merkle.hash_leaf(leaf): leaf for leaf in data_array}\n",
    "        root = Merkle.commit_(hashed_leaves, storage, hash_to_original)\n",
    "        return root, storage, hash_to_original\n",
    "    \n",
    "    @staticmethod\n",
    "    def open_(index, leafs):\n",
    "        assert len(leafs) & (len(leafs) - 1) == 0, \"length must be power of two\"\n",
    "        assert 0 <= index < len(leafs), \"cannot open invalid index\"\n",
    "        if len(leafs) == 2:\n",
    "            return [leafs[1 - index]]\n",
    "        elif index < (len(leafs) / 2):\n",
    "            return Merkle.open_(index, leafs[:len(leafs)//2]) + [Merkle.commit_(leafs[len(leafs)//2:], {}, {})]\n",
    "        else:\n",
    "            return Merkle.open_(index - len(leafs)//2, leafs[len(leafs)//2:]) + [Merkle.commit_(leafs[:len(leafs)//2], {}, {})]\n",
    "\n",
    "    @staticmethod\n",
    "    def open(index, data_array):\n",
    "        return Merkle.open_(index, [Merkle.hash_leaf(leaf) for leaf in data_array])\n",
    "    \n",
    "    @staticmethod\n",
    "    def verify_(root, index, path, leaf):\n",
    "        assert 0 <= index < (1 << len(path)), \"cannot verify invalid index\"\n",
    "        if len(path) == 1:\n",
    "            if index == 0:\n",
    "                return root == Merkle.hash_node(leaf, path[0])\n",
    "            else:\n",
    "                return root == Merkle.hash_node(path[0], leaf)\n",
    "        else:\n",
    "            if index % 2 == 0:\n",
    "                return Merkle.verify_(root, index >> 1, path[1:], Merkle.hash_node(leaf, path[0]))\n",
    "            else:\n",
    "                return Merkle.verify_(root, index >> 1, path[1:], Merkle.hash_node(path[0], leaf))\n",
    "\n",
    "    @staticmethod\n",
    "    def verify(root, index, path, data_element):\n",
    "        return Merkle.verify_(root, index, path, Merkle.hash_leaf(data_element))\n",
    "\n",
    "# Example usage\n",
    "data_array = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "\n",
    "# 1. Commit the Merkle Tree and get the root\n",
    "root, storage, hash_to_original = Merkle.commit(data_array)\n",
    "print(\"Merkle Root:\", root)\n",
    "\n",
    "# Print the hash to original value mapping\n",
    "print(\"\\nMerkle Tree Hash Mapping:\")\n",
    "for k, v in hash_to_original.items():\n",
    "    print(f\"Hash: {k} -> Original Value: {v}\")\n",
    "\n",
    "# 2. Open a leaf to get its Merkle proof\n",
    "index_to_open = 1  # Index of 'b'\n",
    "proof = Merkle.open(index_to_open, data_array)\n",
    "print(\"\\nMerkle Proof for 'b':\", [p for p in proof])\n",
    "\n",
    "# 3. Verify the proof\n",
    "is_valid = Merkle.verify(root, index_to_open, proof, 'b')\n",
    "print(f\"\\nThe value 'b' is {'valid' if is_valid else 'not valid'} in the Merkle tree.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02d934ea-11f8-41eb-ba46-4ecd0fb7728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import blake2b\n",
    "\n",
    "class Merkle:\n",
    "    H = blake2b\n",
    "\n",
    "    def commit_( leafs ):\n",
    "        assert(len(leafs) & (len(leafs)-1) == 0), \"length must be power of two\"\n",
    "        if len(leafs) == 1:\n",
    "            return leafs[0]\n",
    "        else:\n",
    "            return Merkle.H(Merkle.commit_(leafs[:len(leafs)//2]) + Merkle.commit_(leafs[len(leafs)//2:])).digest()\n",
    "\n",
    "    def commit( data_array ):\n",
    "        return Merkle.commit_([Merkle.H(bytes(da)).digest() for da in data_array])\n",
    "    \n",
    "    def open_( index, leafs ):\n",
    "        assert(len(leafs) & (len(leafs)-1) == 0), \"length must be power of two\"\n",
    "        assert(0 <= index and index < len(leafs)), \"cannot open invalid index\"\n",
    "        if len(leafs) == 2:\n",
    "            return [leafs[1 - index]]\n",
    "        elif index < (len(leafs)/2):\n",
    "            return Merkle.open_(index, leafs[:len(leafs)//2]) + [Merkle.commit_(leafs[len(leafs)//2:])]\n",
    "        else:\n",
    "            return Merkle.open_(index - len(leafs)//2, leafs[len(leafs)//2:]) + [Merkle.commit_(leafs[:len(leafs)//2])]\n",
    "\n",
    "    def open( index, data_array ):\n",
    "        return Merkle.open_(index, [Merkle.H(bytes(da)).digest() for da in data_array])\n",
    "    \n",
    "    def verify_( root, index, path, leaf ):\n",
    "        assert(0 <= index and index < (1 << len(path))), \"cannot verify invalid index\"\n",
    "        if len(path) == 1:\n",
    "            if index == 0:\n",
    "                return root == Merkle.H(leaf + path[0]).digest()\n",
    "            else:\n",
    "                return root == Merkle.H(path[0] + leaf).digest()\n",
    "        else:\n",
    "            if index % 2 == 0:\n",
    "                return Merkle.verify_(root, index >> 1, path[1:], Merkle.H(leaf + path[0]).digest())\n",
    "            else:\n",
    "                return Merkle.verify_(root, index >> 1, path[1:], Merkle.H(path[0] + leaf).digest())\n",
    "\n",
    "    def verify( root, index, path, data_element ):\n",
    "        return Merkle.verify_(root, index, path, Merkle.H(bytes(data_element)).digest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0173832f-9c91-4a55-bf8e-360a54c073ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import urandom\n",
    "n = 64\n",
    "leafs = [urandom(int(urandom(1)[0])) for i in range(n)]\n",
    "root = Merkle.commit_(leafs)\n",
    "\n",
    "for i in range(n):\n",
    "        path = Merkle.open_(i, leafs)\n",
    "        assert(Merkle.verify_(root, i, path, leafs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff58486-7447-4ca8-8b7c-bf7d10f2d8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a31b3f1c-e5dc-42fe-b233-d02b4bbc320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web3 import Web3\n",
    "from collections import deque\n",
    "\n",
    "# 創建一個 Web3 實例\n",
    "w3 = Web3()\n",
    "\n",
    "class Merkle:\n",
    "\n",
    "    @staticmethod\n",
    "    def hash_leaf(leaf):\n",
    "        return w3.solidity_keccak(['string'], [leaf]).hex()\n",
    "    \n",
    "    @staticmethod\n",
    "    def hash_node(left, right):\n",
    "        return w3.solidity_keccak(['bytes32', 'bytes32'], [left, right]).hex()\n",
    "\n",
    "    @staticmethod\n",
    "    def commit_(leafs, data_hash):\n",
    "        assert len(leafs) & (len(leafs) - 1) == 0, \"length must be power of two\"\n",
    "        if len(leafs) == 1:\n",
    "            return leafs[0]\n",
    "        else:\n",
    "            left_hash = Merkle.commit_(leafs[:len(leafs)//2], data_hash)\n",
    "            right_hash = Merkle.commit_(leafs[len(leafs)//2:], data_hash)\n",
    "            combined_hash = Merkle.hash_node(left_hash, right_hash)\n",
    "            \n",
    "            # Store original values for intermediate nodes, ensure the mapping exists\n",
    "            data_hash.setdefault(left_hash, left_hash)\n",
    "            data_hash.setdefault(right_hash, right_hash)\n",
    "            data_hash[combined_hash] = (data_hash[left_hash], data_hash[right_hash])\n",
    "            return combined_hash\n",
    "\n",
    "    @staticmethod\n",
    "    def commit(data_array):\n",
    "        hashed_leaves = [Merkle.hash_leaf(leaf) for leaf in data_array]\n",
    "        data_hash = {Merkle.hash_leaf(leaf): leaf for leaf in data_array}\n",
    "        root = Merkle.commit_(hashed_leaves, data_hash)\n",
    "        return root, data_hash\n",
    "    \n",
    "    @staticmethod\n",
    "    def open_(index, leafs):\n",
    "        assert len(leafs) & (len(leafs) - 1) == 0, \"length must be power of two\"\n",
    "        assert 0 <= index < len(leafs), \"cannot open invalid index\"\n",
    "        if len(leafs) == 2:\n",
    "            return [leafs[1 - index]]\n",
    "        elif index < (len(leafs) / 2):\n",
    "            return Merkle.open_(index, leafs[:len(leafs)//2]) + [Merkle.commit_(leafs[len(leafs)//2:], {})]\n",
    "        else:\n",
    "            return Merkle.open_(index - len(leafs)//2, leafs[len(leafs)//2:]) + [Merkle.commit_(leafs[:len(leafs)//2], {})]\n",
    "\n",
    "    @staticmethod\n",
    "    def open(index, data_array):\n",
    "        return Merkle.open_(index, [Merkle.hash_leaf(leaf) for leaf in data_array])\n",
    "    \n",
    "    @staticmethod\n",
    "    def verify_(root, index, path, leaf):\n",
    "        assert 0 <= index < (1 << len(path)), \"cannot verify invalid index\"\n",
    "        if len(path) == 1:\n",
    "            if index == 0:\n",
    "                return root == Merkle.hash_node(leaf, path[0])\n",
    "            else:\n",
    "                return root == Merkle.hash_node(path[0], leaf)\n",
    "        else:\n",
    "            if index % 2 == 0:\n",
    "                return Merkle.verify_(root, index >> 1, path[1:], Merkle.hash_node(leaf, path[0]))\n",
    "            else:\n",
    "                return Merkle.verify_(root, index >> 1, path[1:], Merkle.hash_node(path[0], leaf))\n",
    "\n",
    "    @staticmethod\n",
    "    def verify(root, index, path, data_element):\n",
    "        return Merkle.verify_(root, index, path, Merkle.hash_leaf(data_element))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e875599-e0ed-4e8d-9ee9-f14cfcc0c8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0xcd07272f4955ddcfdac38ff36dff9d3e4353498923679ab548ba87e34648e4a3\n",
      "0xd1e8aeb79500496ef3dc2e57ba746a8315d048b7a664a2bf948db4fa91960483\n",
      "f\n",
      "['0xa8982c89d80987fb9a510e25981ee9170206be21af3c8e0eb312ef1d3382e761', '0xe18a5c2ee5202ecdefed683f03145b1343304dbed01aecb94032b7f801844f0a', '0x68203f90e9d07dc5859259d7536e87a6ba9d345f2552b5b9de2999ddce9ce1bf']\n",
      "3\n",
      "@@  0xcd07272f4955ddcfdac38ff36dff9d3e4353498923679ab548ba87e34648e4a3\n"
     ]
    }
   ],
   "source": [
    "from os import urandom\n",
    "n = 64\n",
    "leafs = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "root, data_hash = Merkle.commit(leafs)\n",
    "\n",
    "#for i in range(len(leafs)):\n",
    "i=5\n",
    "print(root)\n",
    "print(w3.solidity_keccak(['string'], [leafs[i]]).hex())\n",
    "print(leafs[i])\n",
    "\n",
    "path = Merkle.open(i, leafs)\n",
    "print(path)\n",
    "print(len(path))\n",
    "assert(Merkle.verify(root, i, path, leafs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3014001f-96d1-4d28-8c13-766cd3563a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058838ed-eb49-42d6-9185-48061dfb0e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d87d366-9bad-4a4c-9e65-86e927bdb064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "連接狀態: True\n"
     ]
    }
   ],
   "source": [
    "from web3 import Web3\n",
    "import time\n",
    "import json\n",
    "\n",
    "# 連接ganache\n",
    "ganache_url = \"http://localhost:7545\"\n",
    "web3 = Web3(Web3.HTTPProvider(ganache_url))\n",
    "\n",
    "print(f'連接狀態: {web3.is_connected()}')\n",
    "\n",
    "# 合约地址和 ABI\n",
    "contract_address = '0x7b96aF9Bd211cBf6BA5b0dd53aa61Dc5806b6AcE'\n",
    "\n",
    "with open('abi8.json', 'r') as file:\n",
    "    contract_abi = json.load(file) \n",
    "\n",
    "# 创建合约实例\n",
    "contract = web3.eth.contract(address=contract_address, abi=contract_abi)\n",
    "\n",
    "# 监听事件\n",
    "def handle_event(event):\n",
    "    print(f\"Event received: {event}\")\n",
    "    # 调用外部程序或 API 获取数据\n",
    "    data = fetch_data_from_external_source()\n",
    "    # 将数据发送回智能合约\n",
    "    send_data_to_contract(event['args']['caller'], data)\n",
    "\n",
    "def fetch_data_from_external_source():\n",
    "    # 模拟外部数据获取过程\n",
    "    return 42\n",
    "\n",
    "def send_data_to_contract(caller_address, data):\n",
    "    # 使用私钥对交易进行签名\n",
    "    private_key = '0x05bdd1aa1ae4202edd88d25c0c34ae40a1e11ae47f582739e53d67e34ba2284f'\n",
    "    account_address = '0x09ea376Ff3D21010615c4f263a72AF13AEDF77CD'\n",
    "    nonce = web3.eth.get_transaction_count(account_address)\n",
    "    transaction = contract.functions.receiveData(data).build_transaction({\n",
    "        'from': account_address,\n",
    "        'nonce': nonce,\n",
    "        'gas': 2000000,\n",
    "        'gasPrice': web3.to_wei('50', 'gwei')\n",
    "    })\n",
    "    signed_txn = web3.eth.account.sign_transaction(transaction, private_key)\n",
    "    tx_hash = web3.eth.send_raw_transaction(signed_txn.rawTransaction)\n",
    "    print(f\"Transaction sent: {web3.to_hex(tx_hash)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65751fb2-91bf-4a74-9d3d-128385c1da53",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3868\\591131518.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevent_filter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_new_entries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mhandle_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 监听并处理事件\n",
    "event_filter = contract.events.RequestData.create_filter(fromBlock='latest')\n",
    "while True:\n",
    "    for event in event_filter.get_new_entries():\n",
    "        handle_event(event)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d62261-ec11-4210-b631-f868e5a0732b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4814822-52d2-400c-935b-0cd10c60385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 触发 requestData 事件\n",
    "def trigger_request_data():\n",
    "    # 使用私钥对交易进行签名\n",
    "    private_key = '0x6f66f3fa08379a98c0e1f92e6a9dedf1252a503f4faf33c45b51e4bdc121840a'\n",
    "    account = web3.eth.account.privateKeyToAccount(private_key)\n",
    "    transaction = contract.functions.requestData().buildTransaction({\n",
    "        'from': account.address,\n",
    "        'nonce': web3.eth.get_transaction_count(account.address),\n",
    "        'gas': 2000000,\n",
    "        'gasPrice': web3.toWei('50', 'gwei')\n",
    "    })\n",
    "    signed_txn = web3.eth.account.sign_transaction(transaction, private_key)\n",
    "    tx_hash = web3.eth.send_raw_transaction(signed_txn.rawTransaction)\n",
    "    print(f\"requestData Transaction sent: {web3.to_hex(tx_hash)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad2db37-ef85-4509-bc93-2ee345342af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08d2b2dc-b61b-470d-b380-30d41d46f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Crypto.Cipher import AES\n",
    "from Crypto.Random import get_random_bytes\n",
    "from Crypto.Util.Padding import pad, unpad\n",
    "\n",
    "def generate_key():\n",
    "    return get_random_bytes(32)\n",
    "\n",
    "def encrypt(data, key):\n",
    "    cipher = AES.new(key, AES.MODE_CBC)\n",
    "    ciphertext = cipher.encrypt(pad(data.encode('utf-8'), AES.block_size))\n",
    "    iv = cipher.iv\n",
    "    return ciphertext, iv\n",
    "\n",
    "def decrypt(ciphertext, key, iv):\n",
    "    cipher = AES.new(key, AES.MODE_CBC, iv)\n",
    "    decrypted_data = unpad(cipher.decrypt(ciphertext), AES.block_size)\n",
    "    return decrypted_data.decode('utf-8')\n",
    "\n",
    "with open(\"key.txt\", \"rb\") as f:\n",
    "    key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7214f9c7-1dc0-4b87-b190-654ba6740b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating event filter\n",
      "Starting event loop\n",
      "Event received: AttributeDict({'args': AttributeDict({'message': 'Requesting data from external source', 'caller': '0x7439a45be3a121e74Ef79b504dE0200b8260D9c3', 'op': 'x1zJYloCafgAAQgkVWUeCKDg6+E0bPtO3OnK1eftw4DUKV9QnGbQL2RvSecCuY/8GfGVIlSWn+pv5X8keM9ywNO7MzoUIwznjLpJgGWQrlk=,NjPRvwXeiCUeSc46KXIbsg=='}), 'event': 'RequestData', 'logIndex': 0, 'transactionIndex': 0, 'transactionHash': HexBytes('0xbfd7b24f236986f7ec0b79e1fba3834d1403a691e1591987801da6c6afe7c1f9'), 'address': '0xc5bcbf93E511e406828828830521aE3b267137B0', 'blockHash': HexBytes('0xa822f682efa2f3ba163110253911cbf8ee604393fa2c29d6300df4f23ec4d390'), 'blockNumber': 692})\n",
      "Transaction sent: 0x2e8430cc62ee523522b46b550a075d3c44dca56364eaa3952a6c227dbb145ea0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2172\\2237792978.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m# 启动事件监听\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0mlisten_for_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2172\\2237792978.py\u001b[0m in \u001b[0;36mlisten_for_events\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevent_filter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_new_entries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mhandle_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from web3 import Web3\n",
    "import time\n",
    "import json\n",
    "import base64\n",
    "\n",
    "ganache_url = \"http://localhost:7545\"\n",
    "web3 = Web3(Web3.HTTPProvider(ganache_url))\n",
    "\n",
    "# 检查连接\n",
    "if not web3.is_connected():\n",
    "    print(\"Unable to connect to Ethereum node.\")\n",
    "    exit()\n",
    "\n",
    "# 合约地址和 ABI\n",
    "contract_address = '0xc5bcbf93E511e406828828830521aE3b267137B0'\n",
    "with open('abi8.json', 'r') as file:\n",
    "    contract_abi = json.load(file) \n",
    "\n",
    "# 创建合约实例\n",
    "contract = web3.eth.contract(address=contract_address, abi=contract_abi)\n",
    "\n",
    "# 监听事件\n",
    "def handle_event(event):\n",
    "    print(f\"Event received: {event}\")\n",
    "    message = event['args']['message']\n",
    "    op = event['args']['op']\n",
    "    # 调用外部程序或 API 获取数据\n",
    "    data = fetch_data_from_external_source(op)\n",
    "    # 将数据发送回智能合约\n",
    "    send_data_to_contract(event['args']['caller'], data)\n",
    "\n",
    "def fetch_data_from_external_source(op):\n",
    "    # 模拟外部数据获取过程\n",
    "    encrypted_data, iv_data = op.strip().split(\",\")\n",
    "    decrypted_data = decrypt(base64.b64decode(encrypted_data), key, base64.b64decode(iv_data))\n",
    "    hash_data = web3.solidity_keccak(['string'], [decrypted_data]).hex()\n",
    "    return hash_data\n",
    "\n",
    "def send_data_to_contract(caller_address, data):\n",
    "    # 使用私钥对交易进行签名\n",
    "    private_key = '0x05bdd1aa1ae4202edd88d25c0c34ae40a1e11ae47f582739e53d67e34ba2284f'\n",
    "    account_address = '0x09ea376Ff3D21010615c4f263a72AF13AEDF77CD'\n",
    "    nonce = web3.eth.get_transaction_count(account_address)\n",
    "    transaction = contract.functions.receiveData(data).build_transaction({\n",
    "        'from': account_address,\n",
    "        'nonce': nonce,\n",
    "        'gas': 2000000,\n",
    "        'gasPrice': web3.to_wei('50', 'gwei')\n",
    "    })\n",
    "    signed_txn = web3.eth.account.sign_transaction(transaction, private_key)\n",
    "    tx_hash = web3.eth.send_raw_transaction(signed_txn.rawTransaction)\n",
    "    print(f\"Transaction sent: {web3.to_hex(tx_hash)}\")\n",
    "\n",
    "# 监听并处理事件\n",
    "def listen_for_events():\n",
    "    print(\"Creating event filter\")\n",
    "    event_filter = contract.events.RequestData.create_filter(fromBlock='latest')\n",
    "    print(\"Starting event loop\")\n",
    "    while True:\n",
    "        #print(\"Checking for new events\")\n",
    "        for event in event_filter.get_new_entries():\n",
    "            handle_event(event)\n",
    "        time.sleep(2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 启动事件监听\n",
    "    listen_for_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9707cf07-67c7-4301-ab00-ac3f9fa5d538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'X\\xde\\x9d\\x1f\\x028|\\x03\\xfc\\x8bCD\\xa5\\xf9\\x0c\\xe2\\x87\\xc6\\x11F\"\\xda\\xaa\\xcfF\\xfc|\\x16+-\\xfd\\x96'\n"
     ]
    }
   ],
   "source": [
    "result = contract.functions.getA().call()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bddca1-917d-4f13-80cd-12e77309136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 触发 requestData 事件\n",
    "def trigger_request_data():\n",
    "    # 使用私钥对交易进行签名\n",
    "    private_key = '0x6f66f3fa08379a98c0e1f92e6a9dedf1252a503f4faf33c45b51e4bdc121840a'\n",
    "    account_address = '0x7439a45be3a121e74Ef79b504dE0200b8260D9c3'\n",
    "    nonce = web3.eth.get_transaction_count(account_address)\n",
    "    transaction = contract.functions.requestData().build_transaction({\n",
    "        'from': account_address,\n",
    "        'nonce': nonce,\n",
    "        'gas': 2000000,\n",
    "        'gasPrice': web3.to_wei('50', 'gwei')\n",
    "    })\n",
    "    signed_txn = web3.eth.account.sign_transaction(transaction, private_key)\n",
    "    tx_hash = web3.eth.send_raw_transaction(signed_txn.rawTransaction)\n",
    "    print(f\"requestData Transaction sent: {web3.to_hex(tx_hash)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5564a492-caec-4bae-a646-2ca74b3e08cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Crypto.Cipher import AES\n",
    "from Crypto.Util.Padding import unpad\n",
    "\n",
    "def decrypt_parts(encrypted_parts, key):\n",
    "    decrypted_parts = []\n",
    "    for encrypted_part in encrypted_parts:\n",
    "        iv = encrypted_part[:16]\n",
    "        encrypted_data = encrypted_part[16:]\n",
    "        cipher = AES.new(key, AES.MODE_CBC, iv)\n",
    "        decrypted_part = unpad(cipher.decrypt(encrypted_data), AES.block_size)\n",
    "        decrypted_parts.append(decrypted_part)\n",
    "    return decrypted_parts\n",
    "\n",
    "def combine_parts(parts, output_file):\n",
    "    with open(output_file, 'wb') as f:\n",
    "        for part in parts:\n",
    "            f.write(part)\n",
    "\n",
    "def main():\n",
    "    num_parts = 8\n",
    "    # 檔案類型\n",
    "    with open('output_extension.txt', 'r') as f:\n",
    "        output_extension = f.read()\n",
    "    # key\n",
    "    with open('encryption_key.bin', 'rb') as f:\n",
    "        key = f.read()\n",
    "\n",
    "    # Read encrypted parts from files\n",
    "    read_encrypted_parts = []\n",
    "    for i in range(num_parts):\n",
    "        with open(f'encrypted_part_{i}.bin', 'rb') as f:\n",
    "            part = f.read()\n",
    "        read_encrypted_parts.append(part)\n",
    "\n",
    "    # Decrypt each part\n",
    "    decrypted_parts = decrypt_parts(read_encrypted_parts, key)\n",
    "\n",
    "    # Combine decrypted parts back into the original file\n",
    "    combined_file_path = 'decrypted_combined' + output_extension\n",
    "    combine_parts(decrypted_parts, combined_file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76660b7a-a1a6-4e2b-9cac-eb4acb262e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
